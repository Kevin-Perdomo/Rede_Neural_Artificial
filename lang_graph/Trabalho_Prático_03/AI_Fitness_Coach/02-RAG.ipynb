{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67d8090a",
   "metadata": {},
   "source": [
    "# 🧠 **02 - RAG: Sistema de Recuperação Semântica**\n",
    "\n",
    "## 🎯 **Objetivo:**\n",
    "Implementar sistema RAG completo para recuperação inteligente de conhecimento fitness.\n",
    "\n",
    "## 📋 **O que faremos:**\n",
    "1. 🔄 Carregar embeddings da etapa anterior\n",
    "2. 🔍 Implementar busca semântica avançada\n",
    "3. 🎯 Criar contexto personalizado por objetivo\n",
    "4. ✅ Testes de recuperação de informações\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b6ef76",
   "metadata": {},
   "source": [
    "## 1️⃣ **Carregamento dos Dados Processados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea89ae46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SentenceTransformers disponível\n",
      "📦 Imports realizados!\n"
     ]
    }
   ],
   "source": [
    "# 📦 IMPORTS E SETUP\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any, Tuple\n",
    "import hashlib\n",
    "import re\n",
    "\n",
    "# Tentar carregar SentenceTransformers\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    print(\"✅ SentenceTransformers disponível\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ SentenceTransformers não disponível\")\n",
    "    SentenceTransformer = None\n",
    "\n",
    "print(\"📦 Imports realizados!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee9acda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chunks carregados: 22 itens\n",
      "\n",
      "📊 Total de chunks disponíveis: 22\n"
     ]
    }
   ],
   "source": [
    "# 🔄 CARREGAR DADOS DA ETAPA ANTERIOR\n",
    "\n",
    "def carregar_dados_processados():\n",
    "    \"\"\"Carrega chunks e recria embeddings se necessário\"\"\"\n",
    "    \n",
    "    # Tentar carregar chunks salvos\n",
    "    arquivo_chunks = Path(\"fitness_chunks.json\")\n",
    "    \n",
    "    if arquivo_chunks.exists():\n",
    "        try:\n",
    "            with open(arquivo_chunks, 'r', encoding='utf-8') as f:\n",
    "                dados = json.load(f)\n",
    "            \n",
    "            print(f\"✅ Chunks carregados: {dados['total_chunks']} itens\")\n",
    "            return dados['chunks']\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erro ao carregar chunks: {e}\")\n",
    "    \n",
    "    # Se não conseguir carregar, processar novamente\n",
    "    print(\"🔄 Processando base de conhecimento...\")\n",
    "    return reprocessar_base()\n",
    "\n",
    "def reprocessar_base():\n",
    "    \"\"\"Reprocessa base de conhecimento se dados não estiverem disponíveis\"\"\"\n",
    "    \n",
    "    # Carregar base fitness\n",
    "    arquivo_base = Path(\"base_conhecimento_fitness.txt\")\n",
    "    \n",
    "    if arquivo_base.exists():\n",
    "        with open(arquivo_base, 'r', encoding='utf-8') as f:\n",
    "            conteudo = f.read()\n",
    "    else:\n",
    "        # Base mínima para demonstração\n",
    "        conteudo = \"\"\"\n",
    "### HIPERTROFIA\n",
    "Séries: 3-4\n",
    "Repetições: 8-12\n",
    "Descanso: 60-90 segundos\n",
    "Volume alto, intensidade moderada.\n",
    "\n",
    "### PEITO\n",
    "**Supino reto**\n",
    "Exercício fundamental para peitoral maior.\n",
    "\n",
    "**Supino inclinado** \n",
    "Foca na porção superior do peitoral.\n",
    "\"\"\"\n",
    "    \n",
    "    # Chunking básico\n",
    "    chunks = []\n",
    "    secoes = conteudo.split('### ')\n",
    "    \n",
    "    for i, secao in enumerate(secoes[1:], 1):  # Pular primeira seção vazia\n",
    "        linhas = secao.strip().split('\\n')\n",
    "        titulo = linhas[0] if linhas else f\"Seção {i}\"\n",
    "        texto_secao = '### ' + secao.strip()\n",
    "        \n",
    "        chunks.append({\n",
    "            'id': len(chunks),\n",
    "            'texto': texto_secao,\n",
    "            'secao': titulo,\n",
    "            'tokens': len(texto_secao.split()),\n",
    "            'hash': hashlib.md5(texto_secao.encode()).hexdigest()[:8]\n",
    "        })\n",
    "    \n",
    "    print(f\"📄 {len(chunks)} chunks criados\")\n",
    "    return chunks\n",
    "\n",
    "# Carregar dados\n",
    "chunks = carregar_dados_processados()\n",
    "print(f\"\\n📊 Total de chunks disponíveis: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b3d1bc",
   "metadata": {},
   "source": [
    "## 2️⃣ **Sistema RAG Avançado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "896bb881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Inicializando sistema RAG...\n",
      "🔄 Carregando modelo de embeddings...\n",
      "✅ Embeddings gerados: (22, 384)\n",
      "\n",
      "✅ Sistema RAG inicializado!\n",
      "📊 Exercícios disponíveis: 26\n",
      "🎯 Objetivos configurados: 4\n",
      "🔍 Método de busca: Semântica\n"
     ]
    }
   ],
   "source": [
    "# 🧠 CLASSE RAG COMPLETA\n",
    "\n",
    "class FitnessRAGSystem:\n",
    "    \"\"\"Sistema RAG completo para conhecimento fitness\"\"\"\n",
    "    \n",
    "    def __init__(self, chunks: List[Dict]):\n",
    "        self.chunks = chunks\n",
    "        self.embedding_model = None\n",
    "        self.embeddings = []\n",
    "        \n",
    "        # Tentar carregar modelo de embeddings\n",
    "        if SentenceTransformer:\n",
    "            self._inicializar_embeddings()\n",
    "        \n",
    "        # Extrair dados estruturados\n",
    "        self.exercicios_por_grupo = self._extrair_exercicios()\n",
    "        self.principios_por_objetivo = self._extrair_principios()\n",
    "    \n",
    "    def _inicializar_embeddings(self):\n",
    "        \"\"\"Inicializa modelo e gera embeddings\"\"\"\n",
    "        try:\n",
    "            print(\"🔄 Carregando modelo de embeddings...\")\n",
    "            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "            \n",
    "            # Gerar embeddings para todos os chunks\n",
    "            textos = [chunk['texto'] for chunk in self.chunks]\n",
    "            self.embeddings = self.embedding_model.encode(textos)\n",
    "            \n",
    "            # Adicionar embeddings aos chunks\n",
    "            for i, chunk in enumerate(self.chunks):\n",
    "                chunk['embedding'] = self.embeddings[i]\n",
    "            \n",
    "            print(f\"✅ Embeddings gerados: {self.embeddings.shape}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Erro nos embeddings: {e}\")\n",
    "            self.embedding_model = None\n",
    "    \n",
    "    def buscar_contexto(self, query: str, top_k: int = 3, threshold: float = 0.3) -> List[Dict]:\n",
    "        \"\"\"Busca contexto relevante usando similaridade semântica\"\"\"\n",
    "        \n",
    "        if self.embedding_model and self.embeddings.size > 0:\n",
    "            return self._busca_semantica(query, top_k, threshold)\n",
    "        else:\n",
    "            return self._busca_keywords(query, top_k)\n",
    "    \n",
    "    def _busca_semantica(self, query: str, top_k: int, threshold: float) -> List[Dict]:\n",
    "        \"\"\"Busca semântica usando embeddings\"\"\"\n",
    "        try:\n",
    "            # Embedding da query\n",
    "            query_embedding = self.embedding_model.encode([query])[0]\n",
    "            \n",
    "            # Calcular similaridades\n",
    "            similaridades = []\n",
    "            for i, chunk in enumerate(self.chunks):\n",
    "                if 'embedding' in chunk:\n",
    "                    sim = np.dot(query_embedding, chunk['embedding']) / (\n",
    "                        np.linalg.norm(query_embedding) * np.linalg.norm(chunk['embedding'])\n",
    "                    )\n",
    "                    if sim >= threshold:\n",
    "                        similaridades.append((sim, chunk))\n",
    "            \n",
    "            # Ordenar e retornar\n",
    "            similaridades.sort(key=lambda x: x[0], reverse=True)\n",
    "            \n",
    "            resultados = []\n",
    "            for sim, chunk in similaridades[:top_k]:\n",
    "                resultado = chunk.copy()\n",
    "                resultado['score'] = float(sim)\n",
    "                resultado['metodo'] = 'semantica'\n",
    "                resultados.append(resultado)\n",
    "            \n",
    "            return resultados\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erro na busca semântica: {e}\")\n",
    "            return self._busca_keywords(query, top_k)\n",
    "    \n",
    "    def _busca_keywords(self, query: str, top_k: int) -> List[Dict]:\n",
    "        \"\"\"Busca por palavras-chave (fallback)\"\"\"\n",
    "        query_words = set(query.lower().split())\n",
    "        \n",
    "        scores = []\n",
    "        for chunk in self.chunks:\n",
    "            chunk_words = set(chunk['texto'].lower().split())\n",
    "            intersecao = len(query_words.intersection(chunk_words))\n",
    "            \n",
    "            if intersecao > 0:\n",
    "                score = intersecao / len(query_words)\n",
    "                scores.append((score, chunk))\n",
    "        \n",
    "        scores.sort(key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        resultados = []\n",
    "        for score, chunk in scores[:top_k]:\n",
    "            resultado = chunk.copy()\n",
    "            resultado['score'] = float(score)\n",
    "            resultado['metodo'] = 'keywords'\n",
    "            resultados.append(resultado)\n",
    "        \n",
    "        return resultados\n",
    "    \n",
    "    def _extrair_exercicios(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"Extrai exercícios estruturados\"\"\"\n",
    "        exercicios = {\n",
    "            \"peito\": [], \"costas\": [], \"ombros\": [],\n",
    "            \"bracos\": [], \"pernas\": [], \"core\": []\n",
    "        }\n",
    "        \n",
    "        for chunk in self.chunks:\n",
    "            texto = chunk['texto']\n",
    "            secao = chunk.get('secao', '').lower()\n",
    "            \n",
    "            # Detectar grupo muscular\n",
    "            grupo = None\n",
    "            if 'peito' in secao:\n",
    "                grupo = 'peito'\n",
    "            elif 'costa' in secao:\n",
    "                grupo = 'costas'\n",
    "            elif 'ombro' in secao:\n",
    "                grupo = 'ombros'\n",
    "            elif 'braço' in secao:\n",
    "                grupo = 'bracos'\n",
    "            elif 'perna' in secao:\n",
    "                grupo = 'pernas'\n",
    "            elif 'core' in secao or 'abdome' in secao:\n",
    "                grupo = 'core'\n",
    "            \n",
    "            # Extrair exercícios (linhas com **nome**)\n",
    "            if grupo and grupo in exercicios:\n",
    "                linhas = texto.split('\\n')\n",
    "                for linha in linhas:\n",
    "                    if linha.startswith('**') and linha.endswith('**'):\n",
    "                        exercicio = linha.replace('**', '').strip()\n",
    "                        if exercicio and exercicio not in exercicios[grupo]:\n",
    "                            exercicios[grupo].append(exercicio)\n",
    "        \n",
    "        # Fallback se não encontrar\n",
    "        if all(len(lista) == 0 for lista in exercicios.values()):\n",
    "            exercicios = {\n",
    "                \"peito\": [\"Supino reto\", \"Supino inclinado\", \"Crucifixo\"],\n",
    "                \"costas\": [\"Puxada frontal\", \"Remada curvada\", \"Levantamento terra\"],\n",
    "                \"ombros\": [\"Desenvolvimento militar\", \"Elevação lateral\"],\n",
    "                \"bracos\": [\"Rosca direta\", \"Tríceps testa\"],\n",
    "                \"pernas\": [\"Agachamento\", \"Leg press\", \"Stiff\"],\n",
    "                \"core\": [\"Prancha\", \"Abdominal\"]\n",
    "            }\n",
    "        \n",
    "        return exercicios\n",
    "    \n",
    "    def _extrair_principios(self) -> Dict[str, Dict]:\n",
    "        \"\"\"Extrai princípios de treino por objetivo\"\"\"\n",
    "        principios = {\n",
    "            \"hipertrofia\": {\"series\": \"3-4\", \"repeticoes\": \"8-12\", \"descanso\": \"60-90s\"},\n",
    "            \"forca\": {\"series\": \"3-5\", \"repeticoes\": \"1-6\", \"descanso\": \"2-5min\"},\n",
    "            \"emagrecimento\": {\"series\": \"3-4\", \"repeticoes\": \"12-15+\", \"descanso\": \"30-60s\"},\n",
    "            \"condicionamento\": {\"series\": \"3-6\", \"repeticoes\": \"15-25\", \"descanso\": \"15-45s\"}\n",
    "        }\n",
    "        \n",
    "        # Tentar extrair do texto real\n",
    "        for chunk in self.chunks:\n",
    "            texto = chunk['texto'].lower()\n",
    "            secao = chunk.get('secao', '').lower()\n",
    "            \n",
    "            # Detectar objetivo\n",
    "            objetivo = None\n",
    "            if 'hipertrofia' in secao:\n",
    "                objetivo = 'hipertrofia'\n",
    "            elif 'força' in secao or 'forca' in secao:\n",
    "                objetivo = 'forca'\n",
    "            elif 'emagrecimento' in secao:\n",
    "                objetivo = 'emagrecimento'\n",
    "            elif 'condicionamento' in secao:\n",
    "                objetivo = 'condicionamento'\n",
    "            \n",
    "            # Extrair parâmetros se encontrou objetivo\n",
    "            if objetivo and objetivo in principios:\n",
    "                # Buscar séries\n",
    "                series_match = re.search(r'séries?:\\s*(\\d+-?\\d*)', texto)\n",
    "                if series_match:\n",
    "                    principios[objetivo]['series'] = series_match.group(1)\n",
    "                \n",
    "                # Buscar repetições\n",
    "                reps_match = re.search(r'repetições?:\\s*(\\d+-?\\d*\\+?)', texto)\n",
    "                if reps_match:\n",
    "                    principios[objetivo]['repeticoes'] = reps_match.group(1)\n",
    "                \n",
    "                # Buscar descanso\n",
    "                desc_match = re.search(r'descanso:\\s*([\\d-]+\\s*[a-z]+)', texto)\n",
    "                if desc_match:\n",
    "                    principios[objetivo]['descanso'] = desc_match.group(1)\n",
    "        \n",
    "        return principios\n",
    "\n",
    "# Inicializar sistema RAG\n",
    "print(\"🧠 Inicializando sistema RAG...\")\n",
    "rag_system = FitnessRAGSystem(chunks)\n",
    "\n",
    "print(f\"\\n✅ Sistema RAG inicializado!\")\n",
    "print(f\"📊 Exercícios disponíveis: {sum(len(ex) for ex in rag_system.exercicios_por_grupo.values())}\")\n",
    "print(f\"🎯 Objetivos configurados: {len(rag_system.principios_por_objetivo)}\")\n",
    "print(f\"🔍 Método de busca: {'Semântica' if rag_system.embedding_model else 'Keywords'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7a4334",
   "metadata": {},
   "source": [
    "## 3️⃣ **Geração de Contexto Personalizado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70a817b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Função de contexto personalizado criada!\n"
     ]
    }
   ],
   "source": [
    "# 🎯 CONTEXTO PERSONALIZADO POR OBJETIVO\n",
    "\n",
    "def gerar_contexto_personalizado(objetivo: str, periodicidade: int, rag: FitnessRAGSystem) -> Dict[str, Any]:\n",
    "    \"\"\"Gera contexto completo personalizado para o usuário\"\"\"\n",
    "    \n",
    "    print(f\"🎯 Gerando contexto para: {objetivo} ({periodicidade}x/semana)\")\n",
    "    \n",
    "    # Queries específicas para o objetivo\n",
    "    queries = [\n",
    "        f\"treino {objetivo}\",\n",
    "        f\"exercícios {objetivo}\", \n",
    "        f\"séries repetições {objetivo}\",\n",
    "        f\"{periodicidade} dias semana divisão treino\"\n",
    "    ]\n",
    "    \n",
    "    # Buscar informações relevantes\n",
    "    contextos_encontrados = []\n",
    "    for query in queries:\n",
    "        resultados = rag.buscar_contexto(query, top_k=2, threshold=0.2)\n",
    "        for resultado in resultados:\n",
    "            if resultado['score'] > 0.2:  # Filtro de qualidade\n",
    "                contextos_encontrados.append({\n",
    "                    'texto': resultado['texto'],\n",
    "                    'score': resultado['score'],\n",
    "                    'secao': resultado.get('secao', 'Desconhecida'),\n",
    "                    'query_origem': query\n",
    "                })\n",
    "    \n",
    "    # Remover duplicatas mantendo melhor score\n",
    "    contextos_unicos = {}\n",
    "    for ctx in contextos_encontrados:\n",
    "        hash_texto = hashlib.md5(ctx['texto'].encode()).hexdigest()[:8]\n",
    "        if hash_texto not in contextos_unicos or ctx['score'] > contextos_unicos[hash_texto]['score']:\n",
    "            contextos_unicos[hash_texto] = ctx\n",
    "    \n",
    "    # Ordenar por relevância\n",
    "    contextos_finais = sorted(contextos_unicos.values(), key=lambda x: x['score'], reverse=True)[:5]\n",
    "    \n",
    "    # Obter exercícios por grupo muscular\n",
    "    grupos_treino = {\n",
    "        2: [\"peito\", \"costas\"],\n",
    "        3: [\"peito\", \"costas\", \"pernas\"],\n",
    "        4: [\"peito\", \"costas\", \"ombros\", \"pernas\"],\n",
    "        5: [\"peito\", \"costas\", \"ombros\", \"bracos\", \"pernas\"],\n",
    "        6: [\"peito\", \"costas\", \"ombros\", \"bracos\", \"pernas\", \"core\"]\n",
    "    }\n",
    "    \n",
    "    grupos_selecionados = grupos_treino.get(periodicidade, grupos_treino[4])\n",
    "    exercicios_por_grupo = {}\n",
    "    \n",
    "    for grupo in grupos_selecionados:\n",
    "        exercicios = rag.exercicios_por_grupo.get(grupo, [])\n",
    "        exercicios_por_grupo[grupo] = exercicios\n",
    "    \n",
    "    # Obter princípios do objetivo\n",
    "    principios = rag.principios_por_objetivo.get(objetivo, {\n",
    "        \"series\": \"3\", \"repeticoes\": \"10\", \"descanso\": \"60s\"\n",
    "    })\n",
    "    \n",
    "    # Compilar contexto final\n",
    "    contexto = {\n",
    "        'objetivo': objetivo,\n",
    "        'periodicidade': periodicidade,\n",
    "        'contextos_rag': contextos_finais,\n",
    "        'exercicios_por_grupo': exercicios_por_grupo,\n",
    "        'principios_treino': principios,\n",
    "        'resumo_contexto': f\"Contexto para {objetivo} com {len(contextos_finais)} seções relevantes\",\n",
    "        'total_exercicios': sum(len(ex) for ex in exercicios_por_grupo.values()),\n",
    "        'grupos_musculares': list(exercicios_por_grupo.keys())\n",
    "    }\n",
    "    \n",
    "    return contexto\n",
    "\n",
    "print(\"✅ Função de contexto personalizado criada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07301bc4",
   "metadata": {},
   "source": [
    "## 4️⃣ **Testes do Sistema RAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ce30c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 TESTANDO SISTEMA RAG COMPLETO\n",
      "============================================================\n",
      "\n",
      "1️⃣ CENÁRIO: GANHO DE MASSA MUSCULAR\n",
      "----------------------------------------\n",
      "🎯 Gerando contexto para: hipertrofia (4x/semana)\n",
      "\n",
      "📊 RESULTADOS:\n",
      "   • Contextos RAG encontrados: 5\n",
      "   • Exercícios disponíveis: 20\n",
      "   • Grupos musculares: peito, costas, ombros, pernas\n",
      "\n",
      "🎯 PRINCÍPIOS DE TREINO:\n",
      "   • Series: 3-4\n",
      "   • Repeticoes: 8-12\n",
      "   • Descanso: 60-90s\n",
      "\n",
      "🔍 CONTEXTOS MAIS RELEVANTES:\n",
      "   1. Score: 0.610 | Seção: HIPERTROFIA\n",
      "      Texto: ### HIPERTROFIA\n",
      "- **Volume**: Alto (3-4 séries, 8-12 repetições)\n",
      "- **Intensidade...\n",
      "   2. Score: 0.574 | Seção: CARGA PROGRESSIVA\n",
      "      Texto: ### CARGA PROGRESSIVA\n",
      "- Semana 1-2: Adaptação (60-70% carga máxima estimada)\n",
      "- S...\n",
      "\n",
      "💪 EXERCÍCIOS POR GRUPO:\n",
      "   • Peito: Supino reto com barra, Supino inclinado com halteres, Crucifixo inclinado...\n",
      "   • Costas: Puxada frontal, Remada curvada com barra, Remada unilateral com halter...\n",
      "   • Ombros: Desenvolvimento militar, Elevação lateral, Elevação posterior...\n",
      "   • Pernas: Agachamento, Leg press, Passada (afundo)...\n",
      "\n",
      "2️⃣ CENÁRIO: PERDA DE GORDURA\n",
      "----------------------------------------\n",
      "🎯 Gerando contexto para: emagrecimento (5x/semana)\n",
      "\n",
      "📊 RESULTADOS:\n",
      "   • Contextos RAG encontrados: 5\n",
      "   • Exercícios disponíveis: 26\n",
      "   • Grupos musculares: peito, costas, ombros, bracos, pernas\n",
      "\n",
      "🎯 PRINCÍPIOS DE TREINO:\n",
      "   • Series: 3-4\n",
      "   • Repeticoes: 12-15+\n",
      "   • Descanso: 30-60s\n",
      "\n",
      "🔍 CONTEXTOS MAIS RELEVANTES:\n",
      "   1. Score: 0.568 | Seção: CARGA PROGRESSIVA\n",
      "      Texto: ### CARGA PROGRESSIVA\n",
      "- Semana 1-2: Adaptação (60-70% carga máxima estimada)\n",
      "- S...\n",
      "   2. Score: 0.528 | Seção: 2x POR SEMANA - FULL BODY\n",
      "      Texto: ### 2x POR SEMANA - FULL BODY\n",
      "**Dia A:** Agachamento, Supino, Puxada, Desenvolvi...\n",
      "\n",
      "💪 EXERCÍCIOS POR GRUPO:\n",
      "   • Peito: Supino reto com barra, Supino inclinado com halteres, Crucifixo inclinado...\n",
      "   • Costas: Puxada frontal, Remada curvada com barra, Remada unilateral com halter...\n",
      "   • Ombros: Desenvolvimento militar, Elevação lateral, Elevação posterior...\n",
      "   • Bracos: Rosca direta, Rosca martelo, Rosca concentrada...\n",
      "   • Pernas: Agachamento, Leg press, Passada (afundo)...\n",
      "\n",
      "3️⃣ CENÁRIO: GANHO DE FORÇA\n",
      "----------------------------------------\n",
      "🎯 Gerando contexto para: forca (3x/semana)\n",
      "\n",
      "📊 RESULTADOS:\n",
      "   • Contextos RAG encontrados: 4\n",
      "   • Exercícios disponíveis: 16\n",
      "   • Grupos musculares: peito, costas, pernas\n",
      "\n",
      "🎯 PRINCÍPIOS DE TREINO:\n",
      "   • Series: 3-5\n",
      "   • Repeticoes: 1-6\n",
      "   • Descanso: 2-5min\n",
      "\n",
      "🔍 CONTEXTOS MAIS RELEVANTES:\n",
      "   1. Score: 0.574 | Seção: FORÇA\n",
      "      Texto: ### FORÇA\n",
      "- **Volume**: Moderado (3-5 séries, 1-6 repetições)\n",
      "- **Intensidade**:...\n",
      "   2. Score: 0.573 | Seção: CARGA PROGRESSIVA\n",
      "      Texto: ### CARGA PROGRESSIVA\n",
      "- Semana 1-2: Adaptação (60-70% carga máxima estimada)\n",
      "- S...\n",
      "\n",
      "💪 EXERCÍCIOS POR GRUPO:\n",
      "   • Peito: Supino reto com barra, Supino inclinado com halteres, Crucifixo inclinado...\n",
      "   • Costas: Puxada frontal, Remada curvada com barra, Remada unilateral com halter...\n",
      "   • Pernas: Agachamento, Leg press, Passada (afundo)...\n",
      "\n",
      "============================================================\n",
      "✅ Testes do sistema RAG concluídos!\n"
     ]
    }
   ],
   "source": [
    "# 🧪 TESTES DO SISTEMA RAG\n",
    "\n",
    "print(\"🧪 TESTANDO SISTEMA RAG COMPLETO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Cenários de teste\n",
    "cenarios_teste = [\n",
    "    {\"objetivo\": \"hipertrofia\", \"periodicidade\": 4, \"desc\": \"Ganho de massa muscular\"},\n",
    "    {\"objetivo\": \"emagrecimento\", \"periodicidade\": 5, \"desc\": \"Perda de gordura\"},\n",
    "    {\"objetivo\": \"forca\", \"periodicidade\": 3, \"desc\": \"Ganho de força\"}\n",
    "]\n",
    "\n",
    "for i, cenario in enumerate(cenarios_teste, 1):\n",
    "    print(f\"\\n{i}️⃣ CENÁRIO: {cenario['desc'].upper()}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Gerar contexto personalizado\n",
    "    contexto = gerar_contexto_personalizado(\n",
    "        cenario['objetivo'], \n",
    "        cenario['periodicidade'], \n",
    "        rag_system\n",
    "    )\n",
    "    \n",
    "    # Exibir resultados\n",
    "    print(f\"\\n📊 RESULTADOS:\")\n",
    "    print(f\"   • Contextos RAG encontrados: {len(contexto['contextos_rag'])}\")\n",
    "    print(f\"   • Exercícios disponíveis: {contexto['total_exercicios']}\")\n",
    "    print(f\"   • Grupos musculares: {', '.join(contexto['grupos_musculares'])}\")\n",
    "    \n",
    "    print(f\"\\n🎯 PRINCÍPIOS DE TREINO:\")\n",
    "    for param, valor in contexto['principios_treino'].items():\n",
    "        print(f\"   • {param.title()}: {valor}\")\n",
    "    \n",
    "    print(f\"\\n🔍 CONTEXTOS MAIS RELEVANTES:\")\n",
    "    for j, ctx in enumerate(contexto['contextos_rag'][:2], 1):\n",
    "        print(f\"   {j}. Score: {ctx['score']:.3f} | Seção: {ctx['secao']}\")\n",
    "        print(f\"      Texto: {ctx['texto'][:80]}...\")\n",
    "    \n",
    "    print(f\"\\n💪 EXERCÍCIOS POR GRUPO:\")\n",
    "    for grupo, exercicios in contexto['exercicios_por_grupo'].items():\n",
    "        print(f\"   • {grupo.title()}: {', '.join(exercicios[:3])}{'...' if len(exercicios) > 3 else ''}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"✅ Testes do sistema RAG concluídos!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38be6292",
   "metadata": {},
   "source": [
    "## 5️⃣ **Otimização e Cache**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc97e793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sistema de cache inicializado!\n",
      "\n",
      "🧪 Testando cache...\n",
      "🔄 Gerando novo contexto...\n",
      "🎯 Gerando contexto para: hipertrofia (4x/semana)\n",
      "💾 Contexto recuperado do cache\n",
      "\n",
      "📊 Estatísticas do cache:\n",
      "   • size: 1\n",
      "   • hits: 1\n",
      "   • misses: 1\n",
      "   • hit_rate: 50.0%\n"
     ]
    }
   ],
   "source": [
    "# 💾 SISTEMA DE CACHE PARA OTIMIZAÇÃO\n",
    "\n",
    "class RAGCache:\n",
    "    \"\"\"Cache para otimizar consultas RAG frequentes\"\"\"\n",
    "    \n",
    "    def __init__(self, max_size: int = 100):\n",
    "        self.cache = {}\n",
    "        self.max_size = max_size\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "    \n",
    "    def get_cache_key(self, query: str, objetivo: str, periodicidade: int) -> str:\n",
    "        \"\"\"Gera chave única para cache\"\"\"\n",
    "        data = f\"{query}|{objetivo}|{periodicidade}\"\n",
    "        return hashlib.md5(data.encode()).hexdigest()[:16]\n",
    "    \n",
    "    def get(self, query: str, objetivo: str, periodicidade: int) -> Any:\n",
    "        \"\"\"Recupera do cache\"\"\"\n",
    "        key = self.get_cache_key(query, objetivo, periodicidade)\n",
    "        \n",
    "        if key in self.cache:\n",
    "            self.hits += 1\n",
    "            return self.cache[key]\n",
    "        \n",
    "        self.misses += 1\n",
    "        return None\n",
    "    \n",
    "    def put(self, query: str, objetivo: str, periodicidade: int, result: Any):\n",
    "        \"\"\"Armazena no cache\"\"\"\n",
    "        key = self.get_cache_key(query, objetivo, periodicidade)\n",
    "        \n",
    "        # Limpar cache se muito grande\n",
    "        if len(self.cache) >= self.max_size:\n",
    "            # Remove item mais antigo (FIFO simples)\n",
    "            oldest_key = next(iter(self.cache))\n",
    "            del self.cache[oldest_key]\n",
    "        \n",
    "        self.cache[key] = result\n",
    "    \n",
    "    def stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Estatísticas do cache\"\"\"\n",
    "        total = self.hits + self.misses\n",
    "        hit_rate = (self.hits / total * 100) if total > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'size': len(self.cache),\n",
    "            'hits': self.hits,\n",
    "            'misses': self.misses,\n",
    "            'hit_rate': f\"{hit_rate:.1f}%\"\n",
    "        }\n",
    "\n",
    "# Versão otimizada da função de contexto\n",
    "def gerar_contexto_com_cache(objetivo: str, periodicidade: int, rag: FitnessRAGSystem, cache: RAGCache) -> Dict[str, Any]:\n",
    "    \"\"\"Versão otimizada com cache\"\"\"\n",
    "    \n",
    "    # Tentar recuperar do cache\n",
    "    cache_key = f\"contexto_{objetivo}_{periodicidade}\"\n",
    "    resultado_cache = cache.get(cache_key, objetivo, periodicidade)\n",
    "    \n",
    "    if resultado_cache:\n",
    "        print(f\"💾 Contexto recuperado do cache\")\n",
    "        return resultado_cache\n",
    "    \n",
    "    # Gerar novo contexto\n",
    "    print(f\"🔄 Gerando novo contexto...\")\n",
    "    contexto = gerar_contexto_personalizado(objetivo, periodicidade, rag)\n",
    "    \n",
    "    # Salvar no cache\n",
    "    cache.put(cache_key, objetivo, periodicidade, contexto)\n",
    "    \n",
    "    return contexto\n",
    "\n",
    "# Inicializar cache\n",
    "cache_rag = RAGCache(max_size=50)\n",
    "print(\"✅ Sistema de cache inicializado!\")\n",
    "\n",
    "# Teste do cache\n",
    "print(\"\\n🧪 Testando cache...\")\n",
    "\n",
    "# Primeira chamada (miss)\n",
    "ctx1 = gerar_contexto_com_cache(\"hipertrofia\", 4, rag_system, cache_rag)\n",
    "\n",
    "# Segunda chamada (hit)\n",
    "ctx2 = gerar_contexto_com_cache(\"hipertrofia\", 4, rag_system, cache_rag)\n",
    "\n",
    "# Estatísticas\n",
    "stats = cache_rag.stats()\n",
    "print(f\"\\n📊 Estatísticas do cache:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"   • {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700ef24e",
   "metadata": {},
   "source": [
    "## 📊 **Resumo da Etapa 02**\n",
    "\n",
    "### ✅ **Conquistas:**\n",
    "- 🧠 Sistema RAG completo implementado\n",
    "- 🔍 Busca semântica com embeddings funcionando\n",
    "- 🎯 Contexto personalizado por objetivo e periodicidade\n",
    "- 💾 Sistema de cache para otimização\n",
    "- 📊 Extração automática de exercícios e princípios\n",
    "\n",
    "### 🎯 **Funcionalidades Principais:**\n",
    "- **Busca Semântica**: Similaridade coseno com embeddings\n",
    "- **Fallback Robusto**: Busca por keywords quando necessário\n",
    "- **Contexto Inteligente**: Personalizado para cada usuário\n",
    "- **Cache Eficiente**: Otimização de consultas repetidas\n",
    "- **Estruturas Híbridas**: Combina RAG com dados estruturados\n",
    "\n",
    "---\n",
    "\n",
    "🧠 **Sistema RAG fitness pronto para integração!** 🏋️‍♂️"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
