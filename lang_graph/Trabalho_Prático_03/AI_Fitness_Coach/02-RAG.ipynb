{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67d8090a",
   "metadata": {},
   "source": [
    "# ğŸ§  **02 - RAG: Sistema de RecuperaÃ§Ã£o SemÃ¢ntica**\n",
    "\n",
    "## ğŸ¯ **Objetivo:**\n",
    "Implementar sistema RAG completo para recuperaÃ§Ã£o inteligente de conhecimento fitness.\n",
    "\n",
    "## ğŸ“‹ **O que faremos:**\n",
    "1. ğŸ”„ Carregar embeddings da etapa anterior\n",
    "2. ğŸ” Implementar busca semÃ¢ntica avanÃ§ada\n",
    "3. ğŸ¯ Criar contexto personalizado por objetivo\n",
    "4. âœ… Testes de recuperaÃ§Ã£o de informaÃ§Ãµes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b6ef76",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ **Carregamento dos Dados Processados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea89ae46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SentenceTransformers disponÃ­vel\n",
      "ğŸ“¦ Imports realizados!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ IMPORTS E SETUP\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any, Tuple\n",
    "import hashlib\n",
    "import re\n",
    "\n",
    "# Tentar carregar SentenceTransformers\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    print(\"âœ… SentenceTransformers disponÃ­vel\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ SentenceTransformers nÃ£o disponÃ­vel\")\n",
    "    SentenceTransformer = None\n",
    "\n",
    "print(\"ğŸ“¦ Imports realizados!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee9acda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chunks carregados: 22 itens\n",
      "\n",
      "ğŸ“Š Total de chunks disponÃ­veis: 22\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”„ CARREGAR DADOS DA ETAPA ANTERIOR\n",
    "\n",
    "def carregar_dados_processados():\n",
    "    \"\"\"Carrega chunks e recria embeddings se necessÃ¡rio\"\"\"\n",
    "    \n",
    "    # Tentar carregar chunks salvos\n",
    "    arquivo_chunks = Path(\"fitness_chunks.json\")\n",
    "    \n",
    "    if arquivo_chunks.exists():\n",
    "        try:\n",
    "            with open(arquivo_chunks, 'r', encoding='utf-8') as f:\n",
    "                dados = json.load(f)\n",
    "            \n",
    "            print(f\"âœ… Chunks carregados: {dados['total_chunks']} itens\")\n",
    "            return dados['chunks']\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erro ao carregar chunks: {e}\")\n",
    "    \n",
    "    # Se nÃ£o conseguir carregar, processar novamente\n",
    "    print(\"ğŸ”„ Processando base de conhecimento...\")\n",
    "    return reprocessar_base()\n",
    "\n",
    "def reprocessar_base():\n",
    "    \"\"\"Reprocessa base de conhecimento se dados nÃ£o estiverem disponÃ­veis\"\"\"\n",
    "    \n",
    "    # Carregar base fitness\n",
    "    arquivo_base = Path(\"base_conhecimento_fitness.txt\")\n",
    "    \n",
    "    if arquivo_base.exists():\n",
    "        with open(arquivo_base, 'r', encoding='utf-8') as f:\n",
    "            conteudo = f.read()\n",
    "    else:\n",
    "        # Base mÃ­nima para demonstraÃ§Ã£o\n",
    "        conteudo = \"\"\"\n",
    "### HIPERTROFIA\n",
    "SÃ©ries: 3-4\n",
    "RepetiÃ§Ãµes: 8-12\n",
    "Descanso: 60-90 segundos\n",
    "Volume alto, intensidade moderada.\n",
    "\n",
    "### PEITO\n",
    "**Supino reto**\n",
    "ExercÃ­cio fundamental para peitoral maior.\n",
    "\n",
    "**Supino inclinado** \n",
    "Foca na porÃ§Ã£o superior do peitoral.\n",
    "\"\"\"\n",
    "    \n",
    "    # Chunking bÃ¡sico\n",
    "    chunks = []\n",
    "    secoes = conteudo.split('### ')\n",
    "    \n",
    "    for i, secao in enumerate(secoes[1:], 1):  # Pular primeira seÃ§Ã£o vazia\n",
    "        linhas = secao.strip().split('\\n')\n",
    "        titulo = linhas[0] if linhas else f\"SeÃ§Ã£o {i}\"\n",
    "        texto_secao = '### ' + secao.strip()\n",
    "        \n",
    "        chunks.append({\n",
    "            'id': len(chunks),\n",
    "            'texto': texto_secao,\n",
    "            'secao': titulo,\n",
    "            'tokens': len(texto_secao.split()),\n",
    "            'hash': hashlib.md5(texto_secao.encode()).hexdigest()[:8]\n",
    "        })\n",
    "    \n",
    "    print(f\"ğŸ“„ {len(chunks)} chunks criados\")\n",
    "    return chunks\n",
    "\n",
    "# Carregar dados\n",
    "chunks = carregar_dados_processados()\n",
    "print(f\"\\nğŸ“Š Total de chunks disponÃ­veis: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b3d1bc",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ **Sistema RAG AvanÃ§ado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "896bb881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  Inicializando sistema RAG...\n",
      "ğŸ”„ Carregando modelo de embeddings...\n",
      "âœ… Embeddings gerados: (22, 384)\n",
      "\n",
      "âœ… Sistema RAG inicializado!\n",
      "ğŸ“Š ExercÃ­cios disponÃ­veis: 26\n",
      "ğŸ¯ Objetivos configurados: 4\n",
      "ğŸ” MÃ©todo de busca: SemÃ¢ntica\n"
     ]
    }
   ],
   "source": [
    "# ğŸ§  CLASSE RAG COMPLETA\n",
    "\n",
    "class FitnessRAGSystem:\n",
    "    \"\"\"Sistema RAG completo para conhecimento fitness\"\"\"\n",
    "    \n",
    "    def __init__(self, chunks: List[Dict]):\n",
    "        self.chunks = chunks\n",
    "        self.embedding_model = None\n",
    "        self.embeddings = []\n",
    "        \n",
    "        # Tentar carregar modelo de embeddings\n",
    "        if SentenceTransformer:\n",
    "            self._inicializar_embeddings()\n",
    "        \n",
    "        # Extrair dados estruturados\n",
    "        self.exercicios_por_grupo = self._extrair_exercicios()\n",
    "        self.principios_por_objetivo = self._extrair_principios()\n",
    "    \n",
    "    def _inicializar_embeddings(self):\n",
    "        \"\"\"Inicializa modelo e gera embeddings\"\"\"\n",
    "        try:\n",
    "            print(\"ğŸ”„ Carregando modelo de embeddings...\")\n",
    "            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "            \n",
    "            # Gerar embeddings para todos os chunks\n",
    "            textos = [chunk['texto'] for chunk in self.chunks]\n",
    "            self.embeddings = self.embedding_model.encode(textos)\n",
    "            \n",
    "            # Adicionar embeddings aos chunks\n",
    "            for i, chunk in enumerate(self.chunks):\n",
    "                chunk['embedding'] = self.embeddings[i]\n",
    "            \n",
    "            print(f\"âœ… Embeddings gerados: {self.embeddings.shape}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Erro nos embeddings: {e}\")\n",
    "            self.embedding_model = None\n",
    "    \n",
    "    def buscar_contexto(self, query: str, top_k: int = 3, threshold: float = 0.3) -> List[Dict]:\n",
    "        \"\"\"Busca contexto relevante usando similaridade semÃ¢ntica\"\"\"\n",
    "        \n",
    "        if self.embedding_model and self.embeddings.size > 0:\n",
    "            return self._busca_semantica(query, top_k, threshold)\n",
    "        else:\n",
    "            return self._busca_keywords(query, top_k)\n",
    "    \n",
    "    def _busca_semantica(self, query: str, top_k: int, threshold: float) -> List[Dict]:\n",
    "        \"\"\"Busca semÃ¢ntica usando embeddings\"\"\"\n",
    "        try:\n",
    "            # Embedding da query\n",
    "            query_embedding = self.embedding_model.encode([query])[0]\n",
    "            \n",
    "            # Calcular similaridades\n",
    "            similaridades = []\n",
    "            for i, chunk in enumerate(self.chunks):\n",
    "                if 'embedding' in chunk:\n",
    "                    sim = np.dot(query_embedding, chunk['embedding']) / (\n",
    "                        np.linalg.norm(query_embedding) * np.linalg.norm(chunk['embedding'])\n",
    "                    )\n",
    "                    if sim >= threshold:\n",
    "                        similaridades.append((sim, chunk))\n",
    "            \n",
    "            # Ordenar e retornar\n",
    "            similaridades.sort(key=lambda x: x[0], reverse=True)\n",
    "            \n",
    "            resultados = []\n",
    "            for sim, chunk in similaridades[:top_k]:\n",
    "                resultado = chunk.copy()\n",
    "                resultado['score'] = float(sim)\n",
    "                resultado['metodo'] = 'semantica'\n",
    "                resultados.append(resultado)\n",
    "            \n",
    "            return resultados\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erro na busca semÃ¢ntica: {e}\")\n",
    "            return self._busca_keywords(query, top_k)\n",
    "    \n",
    "    def _busca_keywords(self, query: str, top_k: int) -> List[Dict]:\n",
    "        \"\"\"Busca por palavras-chave (fallback)\"\"\"\n",
    "        query_words = set(query.lower().split())\n",
    "        \n",
    "        scores = []\n",
    "        for chunk in self.chunks:\n",
    "            chunk_words = set(chunk['texto'].lower().split())\n",
    "            intersecao = len(query_words.intersection(chunk_words))\n",
    "            \n",
    "            if intersecao > 0:\n",
    "                score = intersecao / len(query_words)\n",
    "                scores.append((score, chunk))\n",
    "        \n",
    "        scores.sort(key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        resultados = []\n",
    "        for score, chunk in scores[:top_k]:\n",
    "            resultado = chunk.copy()\n",
    "            resultado['score'] = float(score)\n",
    "            resultado['metodo'] = 'keywords'\n",
    "            resultados.append(resultado)\n",
    "        \n",
    "        return resultados\n",
    "    \n",
    "    def _extrair_exercicios(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"Extrai exercÃ­cios estruturados\"\"\"\n",
    "        exercicios = {\n",
    "            \"peito\": [], \"costas\": [], \"ombros\": [],\n",
    "            \"bracos\": [], \"pernas\": [], \"core\": []\n",
    "        }\n",
    "        \n",
    "        for chunk in self.chunks:\n",
    "            texto = chunk['texto']\n",
    "            secao = chunk.get('secao', '').lower()\n",
    "            \n",
    "            # Detectar grupo muscular\n",
    "            grupo = None\n",
    "            if 'peito' in secao:\n",
    "                grupo = 'peito'\n",
    "            elif 'costa' in secao:\n",
    "                grupo = 'costas'\n",
    "            elif 'ombro' in secao:\n",
    "                grupo = 'ombros'\n",
    "            elif 'braÃ§o' in secao:\n",
    "                grupo = 'bracos'\n",
    "            elif 'perna' in secao:\n",
    "                grupo = 'pernas'\n",
    "            elif 'core' in secao or 'abdome' in secao:\n",
    "                grupo = 'core'\n",
    "            \n",
    "            # Extrair exercÃ­cios (linhas com **nome**)\n",
    "            if grupo and grupo in exercicios:\n",
    "                linhas = texto.split('\\n')\n",
    "                for linha in linhas:\n",
    "                    if linha.startswith('**') and linha.endswith('**'):\n",
    "                        exercicio = linha.replace('**', '').strip()\n",
    "                        if exercicio and exercicio not in exercicios[grupo]:\n",
    "                            exercicios[grupo].append(exercicio)\n",
    "        \n",
    "        # Fallback se nÃ£o encontrar\n",
    "        if all(len(lista) == 0 for lista in exercicios.values()):\n",
    "            exercicios = {\n",
    "                \"peito\": [\"Supino reto\", \"Supino inclinado\", \"Crucifixo\"],\n",
    "                \"costas\": [\"Puxada frontal\", \"Remada curvada\", \"Levantamento terra\"],\n",
    "                \"ombros\": [\"Desenvolvimento militar\", \"ElevaÃ§Ã£o lateral\"],\n",
    "                \"bracos\": [\"Rosca direta\", \"TrÃ­ceps testa\"],\n",
    "                \"pernas\": [\"Agachamento\", \"Leg press\", \"Stiff\"],\n",
    "                \"core\": [\"Prancha\", \"Abdominal\"]\n",
    "            }\n",
    "        \n",
    "        return exercicios\n",
    "    \n",
    "    def _extrair_principios(self) -> Dict[str, Dict]:\n",
    "        \"\"\"Extrai princÃ­pios de treino por objetivo\"\"\"\n",
    "        principios = {\n",
    "            \"hipertrofia\": {\"series\": \"3-4\", \"repeticoes\": \"8-12\", \"descanso\": \"60-90s\"},\n",
    "            \"forca\": {\"series\": \"3-5\", \"repeticoes\": \"1-6\", \"descanso\": \"2-5min\"},\n",
    "            \"emagrecimento\": {\"series\": \"3-4\", \"repeticoes\": \"12-15+\", \"descanso\": \"30-60s\"},\n",
    "            \"condicionamento\": {\"series\": \"3-6\", \"repeticoes\": \"15-25\", \"descanso\": \"15-45s\"}\n",
    "        }\n",
    "        \n",
    "        # Tentar extrair do texto real\n",
    "        for chunk in self.chunks:\n",
    "            texto = chunk['texto'].lower()\n",
    "            secao = chunk.get('secao', '').lower()\n",
    "            \n",
    "            # Detectar objetivo\n",
    "            objetivo = None\n",
    "            if 'hipertrofia' in secao:\n",
    "                objetivo = 'hipertrofia'\n",
    "            elif 'forÃ§a' in secao or 'forca' in secao:\n",
    "                objetivo = 'forca'\n",
    "            elif 'emagrecimento' in secao:\n",
    "                objetivo = 'emagrecimento'\n",
    "            elif 'condicionamento' in secao:\n",
    "                objetivo = 'condicionamento'\n",
    "            \n",
    "            # Extrair parÃ¢metros se encontrou objetivo\n",
    "            if objetivo and objetivo in principios:\n",
    "                # Buscar sÃ©ries\n",
    "                series_match = re.search(r'sÃ©ries?:\\s*(\\d+-?\\d*)', texto)\n",
    "                if series_match:\n",
    "                    principios[objetivo]['series'] = series_match.group(1)\n",
    "                \n",
    "                # Buscar repetiÃ§Ãµes\n",
    "                reps_match = re.search(r'repetiÃ§Ãµes?:\\s*(\\d+-?\\d*\\+?)', texto)\n",
    "                if reps_match:\n",
    "                    principios[objetivo]['repeticoes'] = reps_match.group(1)\n",
    "                \n",
    "                # Buscar descanso\n",
    "                desc_match = re.search(r'descanso:\\s*([\\d-]+\\s*[a-z]+)', texto)\n",
    "                if desc_match:\n",
    "                    principios[objetivo]['descanso'] = desc_match.group(1)\n",
    "        \n",
    "        return principios\n",
    "\n",
    "# Inicializar sistema RAG\n",
    "print(\"ğŸ§  Inicializando sistema RAG...\")\n",
    "rag_system = FitnessRAGSystem(chunks)\n",
    "\n",
    "print(f\"\\nâœ… Sistema RAG inicializado!\")\n",
    "print(f\"ğŸ“Š ExercÃ­cios disponÃ­veis: {sum(len(ex) for ex in rag_system.exercicios_por_grupo.values())}\")\n",
    "print(f\"ğŸ¯ Objetivos configurados: {len(rag_system.principios_por_objetivo)}\")\n",
    "print(f\"ğŸ” MÃ©todo de busca: {'SemÃ¢ntica' if rag_system.embedding_model else 'Keywords'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7a4334",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ **GeraÃ§Ã£o de Contexto Personalizado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70a817b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FunÃ§Ã£o de contexto personalizado criada!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¯ CONTEXTO PERSONALIZADO POR OBJETIVO\n",
    "\n",
    "def gerar_contexto_personalizado(objetivo: str, periodicidade: int, rag: FitnessRAGSystem) -> Dict[str, Any]:\n",
    "    \"\"\"Gera contexto completo personalizado para o usuÃ¡rio\"\"\"\n",
    "    \n",
    "    print(f\"ğŸ¯ Gerando contexto para: {objetivo} ({periodicidade}x/semana)\")\n",
    "    \n",
    "    # Queries especÃ­ficas para o objetivo\n",
    "    queries = [\n",
    "        f\"treino {objetivo}\",\n",
    "        f\"exercÃ­cios {objetivo}\", \n",
    "        f\"sÃ©ries repetiÃ§Ãµes {objetivo}\",\n",
    "        f\"{periodicidade} dias semana divisÃ£o treino\"\n",
    "    ]\n",
    "    \n",
    "    # Buscar informaÃ§Ãµes relevantes\n",
    "    contextos_encontrados = []\n",
    "    for query in queries:\n",
    "        resultados = rag.buscar_contexto(query, top_k=2, threshold=0.2)\n",
    "        for resultado in resultados:\n",
    "            if resultado['score'] > 0.2:  # Filtro de qualidade\n",
    "                contextos_encontrados.append({\n",
    "                    'texto': resultado['texto'],\n",
    "                    'score': resultado['score'],\n",
    "                    'secao': resultado.get('secao', 'Desconhecida'),\n",
    "                    'query_origem': query\n",
    "                })\n",
    "    \n",
    "    # Remover duplicatas mantendo melhor score\n",
    "    contextos_unicos = {}\n",
    "    for ctx in contextos_encontrados:\n",
    "        hash_texto = hashlib.md5(ctx['texto'].encode()).hexdigest()[:8]\n",
    "        if hash_texto not in contextos_unicos or ctx['score'] > contextos_unicos[hash_texto]['score']:\n",
    "            contextos_unicos[hash_texto] = ctx\n",
    "    \n",
    "    # Ordenar por relevÃ¢ncia\n",
    "    contextos_finais = sorted(contextos_unicos.values(), key=lambda x: x['score'], reverse=True)[:5]\n",
    "    \n",
    "    # Obter exercÃ­cios por grupo muscular\n",
    "    grupos_treino = {\n",
    "        2: [\"peito\", \"costas\"],\n",
    "        3: [\"peito\", \"costas\", \"pernas\"],\n",
    "        4: [\"peito\", \"costas\", \"ombros\", \"pernas\"],\n",
    "        5: [\"peito\", \"costas\", \"ombros\", \"bracos\", \"pernas\"],\n",
    "        6: [\"peito\", \"costas\", \"ombros\", \"bracos\", \"pernas\", \"core\"]\n",
    "    }\n",
    "    \n",
    "    grupos_selecionados = grupos_treino.get(periodicidade, grupos_treino[4])\n",
    "    exercicios_por_grupo = {}\n",
    "    \n",
    "    for grupo in grupos_selecionados:\n",
    "        exercicios = rag.exercicios_por_grupo.get(grupo, [])\n",
    "        exercicios_por_grupo[grupo] = exercicios\n",
    "    \n",
    "    # Obter princÃ­pios do objetivo\n",
    "    principios = rag.principios_por_objetivo.get(objetivo, {\n",
    "        \"series\": \"3\", \"repeticoes\": \"10\", \"descanso\": \"60s\"\n",
    "    })\n",
    "    \n",
    "    # Compilar contexto final\n",
    "    contexto = {\n",
    "        'objetivo': objetivo,\n",
    "        'periodicidade': periodicidade,\n",
    "        'contextos_rag': contextos_finais,\n",
    "        'exercicios_por_grupo': exercicios_por_grupo,\n",
    "        'principios_treino': principios,\n",
    "        'resumo_contexto': f\"Contexto para {objetivo} com {len(contextos_finais)} seÃ§Ãµes relevantes\",\n",
    "        'total_exercicios': sum(len(ex) for ex in exercicios_por_grupo.values()),\n",
    "        'grupos_musculares': list(exercicios_por_grupo.keys())\n",
    "    }\n",
    "    \n",
    "    return contexto\n",
    "\n",
    "print(\"âœ… FunÃ§Ã£o de contexto personalizado criada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07301bc4",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ **Testes do Sistema RAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ce30c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª TESTANDO SISTEMA RAG COMPLETO\n",
      "============================================================\n",
      "\n",
      "1ï¸âƒ£ CENÃRIO: GANHO DE MASSA MUSCULAR\n",
      "----------------------------------------\n",
      "ğŸ¯ Gerando contexto para: hipertrofia (4x/semana)\n",
      "\n",
      "ğŸ“Š RESULTADOS:\n",
      "   â€¢ Contextos RAG encontrados: 5\n",
      "   â€¢ ExercÃ­cios disponÃ­veis: 20\n",
      "   â€¢ Grupos musculares: peito, costas, ombros, pernas\n",
      "\n",
      "ğŸ¯ PRINCÃPIOS DE TREINO:\n",
      "   â€¢ Series: 3-4\n",
      "   â€¢ Repeticoes: 8-12\n",
      "   â€¢ Descanso: 60-90s\n",
      "\n",
      "ğŸ” CONTEXTOS MAIS RELEVANTES:\n",
      "   1. Score: 0.610 | SeÃ§Ã£o: HIPERTROFIA\n",
      "      Texto: ### HIPERTROFIA\n",
      "- **Volume**: Alto (3-4 sÃ©ries, 8-12 repetiÃ§Ãµes)\n",
      "- **Intensidade...\n",
      "   2. Score: 0.574 | SeÃ§Ã£o: CARGA PROGRESSIVA\n",
      "      Texto: ### CARGA PROGRESSIVA\n",
      "- Semana 1-2: AdaptaÃ§Ã£o (60-70% carga mÃ¡xima estimada)\n",
      "- S...\n",
      "\n",
      "ğŸ’ª EXERCÃCIOS POR GRUPO:\n",
      "   â€¢ Peito: Supino reto com barra, Supino inclinado com halteres, Crucifixo inclinado...\n",
      "   â€¢ Costas: Puxada frontal, Remada curvada com barra, Remada unilateral com halter...\n",
      "   â€¢ Ombros: Desenvolvimento militar, ElevaÃ§Ã£o lateral, ElevaÃ§Ã£o posterior...\n",
      "   â€¢ Pernas: Agachamento, Leg press, Passada (afundo)...\n",
      "\n",
      "2ï¸âƒ£ CENÃRIO: PERDA DE GORDURA\n",
      "----------------------------------------\n",
      "ğŸ¯ Gerando contexto para: emagrecimento (5x/semana)\n",
      "\n",
      "ğŸ“Š RESULTADOS:\n",
      "   â€¢ Contextos RAG encontrados: 5\n",
      "   â€¢ ExercÃ­cios disponÃ­veis: 26\n",
      "   â€¢ Grupos musculares: peito, costas, ombros, bracos, pernas\n",
      "\n",
      "ğŸ¯ PRINCÃPIOS DE TREINO:\n",
      "   â€¢ Series: 3-4\n",
      "   â€¢ Repeticoes: 12-15+\n",
      "   â€¢ Descanso: 30-60s\n",
      "\n",
      "ğŸ” CONTEXTOS MAIS RELEVANTES:\n",
      "   1. Score: 0.568 | SeÃ§Ã£o: CARGA PROGRESSIVA\n",
      "      Texto: ### CARGA PROGRESSIVA\n",
      "- Semana 1-2: AdaptaÃ§Ã£o (60-70% carga mÃ¡xima estimada)\n",
      "- S...\n",
      "   2. Score: 0.528 | SeÃ§Ã£o: 2x POR SEMANA - FULL BODY\n",
      "      Texto: ### 2x POR SEMANA - FULL BODY\n",
      "**Dia A:** Agachamento, Supino, Puxada, Desenvolvi...\n",
      "\n",
      "ğŸ’ª EXERCÃCIOS POR GRUPO:\n",
      "   â€¢ Peito: Supino reto com barra, Supino inclinado com halteres, Crucifixo inclinado...\n",
      "   â€¢ Costas: Puxada frontal, Remada curvada com barra, Remada unilateral com halter...\n",
      "   â€¢ Ombros: Desenvolvimento militar, ElevaÃ§Ã£o lateral, ElevaÃ§Ã£o posterior...\n",
      "   â€¢ Bracos: Rosca direta, Rosca martelo, Rosca concentrada...\n",
      "   â€¢ Pernas: Agachamento, Leg press, Passada (afundo)...\n",
      "\n",
      "3ï¸âƒ£ CENÃRIO: GANHO DE FORÃ‡A\n",
      "----------------------------------------\n",
      "ğŸ¯ Gerando contexto para: forca (3x/semana)\n",
      "\n",
      "ğŸ“Š RESULTADOS:\n",
      "   â€¢ Contextos RAG encontrados: 4\n",
      "   â€¢ ExercÃ­cios disponÃ­veis: 16\n",
      "   â€¢ Grupos musculares: peito, costas, pernas\n",
      "\n",
      "ğŸ¯ PRINCÃPIOS DE TREINO:\n",
      "   â€¢ Series: 3-5\n",
      "   â€¢ Repeticoes: 1-6\n",
      "   â€¢ Descanso: 2-5min\n",
      "\n",
      "ğŸ” CONTEXTOS MAIS RELEVANTES:\n",
      "   1. Score: 0.574 | SeÃ§Ã£o: FORÃ‡A\n",
      "      Texto: ### FORÃ‡A\n",
      "- **Volume**: Moderado (3-5 sÃ©ries, 1-6 repetiÃ§Ãµes)\n",
      "- **Intensidade**:...\n",
      "   2. Score: 0.573 | SeÃ§Ã£o: CARGA PROGRESSIVA\n",
      "      Texto: ### CARGA PROGRESSIVA\n",
      "- Semana 1-2: AdaptaÃ§Ã£o (60-70% carga mÃ¡xima estimada)\n",
      "- S...\n",
      "\n",
      "ğŸ’ª EXERCÃCIOS POR GRUPO:\n",
      "   â€¢ Peito: Supino reto com barra, Supino inclinado com halteres, Crucifixo inclinado...\n",
      "   â€¢ Costas: Puxada frontal, Remada curvada com barra, Remada unilateral com halter...\n",
      "   â€¢ Pernas: Agachamento, Leg press, Passada (afundo)...\n",
      "\n",
      "============================================================\n",
      "âœ… Testes do sistema RAG concluÃ­dos!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ§ª TESTES DO SISTEMA RAG\n",
    "\n",
    "print(\"ğŸ§ª TESTANDO SISTEMA RAG COMPLETO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# CenÃ¡rios de teste\n",
    "cenarios_teste = [\n",
    "    {\"objetivo\": \"hipertrofia\", \"periodicidade\": 4, \"desc\": \"Ganho de massa muscular\"},\n",
    "    {\"objetivo\": \"emagrecimento\", \"periodicidade\": 5, \"desc\": \"Perda de gordura\"},\n",
    "    {\"objetivo\": \"forca\", \"periodicidade\": 3, \"desc\": \"Ganho de forÃ§a\"}\n",
    "]\n",
    "\n",
    "for i, cenario in enumerate(cenarios_teste, 1):\n",
    "    print(f\"\\n{i}ï¸âƒ£ CENÃRIO: {cenario['desc'].upper()}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Gerar contexto personalizado\n",
    "    contexto = gerar_contexto_personalizado(\n",
    "        cenario['objetivo'], \n",
    "        cenario['periodicidade'], \n",
    "        rag_system\n",
    "    )\n",
    "    \n",
    "    # Exibir resultados\n",
    "    print(f\"\\nğŸ“Š RESULTADOS:\")\n",
    "    print(f\"   â€¢ Contextos RAG encontrados: {len(contexto['contextos_rag'])}\")\n",
    "    print(f\"   â€¢ ExercÃ­cios disponÃ­veis: {contexto['total_exercicios']}\")\n",
    "    print(f\"   â€¢ Grupos musculares: {', '.join(contexto['grupos_musculares'])}\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ PRINCÃPIOS DE TREINO:\")\n",
    "    for param, valor in contexto['principios_treino'].items():\n",
    "        print(f\"   â€¢ {param.title()}: {valor}\")\n",
    "    \n",
    "    print(f\"\\nğŸ” CONTEXTOS MAIS RELEVANTES:\")\n",
    "    for j, ctx in enumerate(contexto['contextos_rag'][:2], 1):\n",
    "        print(f\"   {j}. Score: {ctx['score']:.3f} | SeÃ§Ã£o: {ctx['secao']}\")\n",
    "        print(f\"      Texto: {ctx['texto'][:80]}...\")\n",
    "    \n",
    "    print(f\"\\nğŸ’ª EXERCÃCIOS POR GRUPO:\")\n",
    "    for grupo, exercicios in contexto['exercicios_por_grupo'].items():\n",
    "        print(f\"   â€¢ {grupo.title()}: {', '.join(exercicios[:3])}{'...' if len(exercicios) > 3 else ''}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… Testes do sistema RAG concluÃ­dos!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38be6292",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ **OtimizaÃ§Ã£o e Cache**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc97e793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sistema de cache inicializado!\n",
      "\n",
      "ğŸ§ª Testando cache...\n",
      "ğŸ”„ Gerando novo contexto...\n",
      "ğŸ¯ Gerando contexto para: hipertrofia (4x/semana)\n",
      "ğŸ’¾ Contexto recuperado do cache\n",
      "\n",
      "ğŸ“Š EstatÃ­sticas do cache:\n",
      "   â€¢ size: 1\n",
      "   â€¢ hits: 1\n",
      "   â€¢ misses: 1\n",
      "   â€¢ hit_rate: 50.0%\n"
     ]
    }
   ],
   "source": [
    "# ğŸ’¾ SISTEMA DE CACHE PARA OTIMIZAÃ‡ÃƒO\n",
    "\n",
    "class RAGCache:\n",
    "    \"\"\"Cache para otimizar consultas RAG frequentes\"\"\"\n",
    "    \n",
    "    def __init__(self, max_size: int = 100):\n",
    "        self.cache = {}\n",
    "        self.max_size = max_size\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "    \n",
    "    def get_cache_key(self, query: str, objetivo: str, periodicidade: int) -> str:\n",
    "        \"\"\"Gera chave Ãºnica para cache\"\"\"\n",
    "        data = f\"{query}|{objetivo}|{periodicidade}\"\n",
    "        return hashlib.md5(data.encode()).hexdigest()[:16]\n",
    "    \n",
    "    def get(self, query: str, objetivo: str, periodicidade: int) -> Any:\n",
    "        \"\"\"Recupera do cache\"\"\"\n",
    "        key = self.get_cache_key(query, objetivo, periodicidade)\n",
    "        \n",
    "        if key in self.cache:\n",
    "            self.hits += 1\n",
    "            return self.cache[key]\n",
    "        \n",
    "        self.misses += 1\n",
    "        return None\n",
    "    \n",
    "    def put(self, query: str, objetivo: str, periodicidade: int, result: Any):\n",
    "        \"\"\"Armazena no cache\"\"\"\n",
    "        key = self.get_cache_key(query, objetivo, periodicidade)\n",
    "        \n",
    "        # Limpar cache se muito grande\n",
    "        if len(self.cache) >= self.max_size:\n",
    "            # Remove item mais antigo (FIFO simples)\n",
    "            oldest_key = next(iter(self.cache))\n",
    "            del self.cache[oldest_key]\n",
    "        \n",
    "        self.cache[key] = result\n",
    "    \n",
    "    def stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"EstatÃ­sticas do cache\"\"\"\n",
    "        total = self.hits + self.misses\n",
    "        hit_rate = (self.hits / total * 100) if total > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'size': len(self.cache),\n",
    "            'hits': self.hits,\n",
    "            'misses': self.misses,\n",
    "            'hit_rate': f\"{hit_rate:.1f}%\"\n",
    "        }\n",
    "\n",
    "# VersÃ£o otimizada da funÃ§Ã£o de contexto\n",
    "def gerar_contexto_com_cache(objetivo: str, periodicidade: int, rag: FitnessRAGSystem, cache: RAGCache) -> Dict[str, Any]:\n",
    "    \"\"\"VersÃ£o otimizada com cache\"\"\"\n",
    "    \n",
    "    # Tentar recuperar do cache\n",
    "    cache_key = f\"contexto_{objetivo}_{periodicidade}\"\n",
    "    resultado_cache = cache.get(cache_key, objetivo, periodicidade)\n",
    "    \n",
    "    if resultado_cache:\n",
    "        print(f\"ğŸ’¾ Contexto recuperado do cache\")\n",
    "        return resultado_cache\n",
    "    \n",
    "    # Gerar novo contexto\n",
    "    print(f\"ğŸ”„ Gerando novo contexto...\")\n",
    "    contexto = gerar_contexto_personalizado(objetivo, periodicidade, rag)\n",
    "    \n",
    "    # Salvar no cache\n",
    "    cache.put(cache_key, objetivo, periodicidade, contexto)\n",
    "    \n",
    "    return contexto\n",
    "\n",
    "# Inicializar cache\n",
    "cache_rag = RAGCache(max_size=50)\n",
    "print(\"âœ… Sistema de cache inicializado!\")\n",
    "\n",
    "# Teste do cache\n",
    "print(\"\\nğŸ§ª Testando cache...\")\n",
    "\n",
    "# Primeira chamada (miss)\n",
    "ctx1 = gerar_contexto_com_cache(\"hipertrofia\", 4, rag_system, cache_rag)\n",
    "\n",
    "# Segunda chamada (hit)\n",
    "ctx2 = gerar_contexto_com_cache(\"hipertrofia\", 4, rag_system, cache_rag)\n",
    "\n",
    "# EstatÃ­sticas\n",
    "stats = cache_rag.stats()\n",
    "print(f\"\\nğŸ“Š EstatÃ­sticas do cache:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"   â€¢ {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700ef24e",
   "metadata": {},
   "source": [
    "## ğŸ“Š **Resumo da Etapa 02**\n",
    "\n",
    "### âœ… **Conquistas:**\n",
    "- ğŸ§  Sistema RAG completo implementado\n",
    "- ğŸ” Busca semÃ¢ntica com embeddings funcionando\n",
    "- ğŸ¯ Contexto personalizado por objetivo e periodicidade\n",
    "- ğŸ’¾ Sistema de cache para otimizaÃ§Ã£o\n",
    "- ğŸ“Š ExtraÃ§Ã£o automÃ¡tica de exercÃ­cios e princÃ­pios\n",
    "\n",
    "### ğŸ¯ **Funcionalidades Principais:**\n",
    "- **Busca SemÃ¢ntica**: Similaridade coseno com embeddings\n",
    "- **Fallback Robusto**: Busca por keywords quando necessÃ¡rio\n",
    "- **Contexto Inteligente**: Personalizado para cada usuÃ¡rio\n",
    "- **Cache Eficiente**: OtimizaÃ§Ã£o de consultas repetidas\n",
    "- **Estruturas HÃ­bridas**: Combina RAG com dados estruturados\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ§  **Sistema RAG fitness pronto para integraÃ§Ã£o!** ğŸ‹ï¸â€â™‚ï¸"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
