{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "#from langchain_openai import OpenAIEmbeddings\n",
    "from numpy import dot, array\n",
    "from numpy.linalg import norm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Este é o primeiro documento. Ele contém informações importantes sobre o projeto.\",\n",
    "    \"Este é o segundo documento. Ele contém informações importantes sobre o projeto.\",\n",
    "    \"O terceiro documento oferece uma visão geral dos resultados esperados e métricas de sucesso.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir documentos em chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50,  \n",
    "    chunk_overlap=10,\n",
    "    length_function=len\n",
    ")\n",
    "chunks = text_splitter.create_documents(documents)\n",
    "\n",
    "print(\"\\nChunks gerados:\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}: {chunk.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nNúmero total de chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "#print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedded_chunks = embeddings.embed_documents([chunk.page_content for chunk in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma lista para armazenar os embeddings\n",
    "embedded_chunks = []\n",
    "for chunk in chunks:\n",
    "    # A biblioteca de embeddings transforma o texto em um vetor numérico\n",
    "    embedding = embeddings_model.embed_documents([chunk.page_content])[0]\n",
    "    embedded_chunks.append(embedding)\n",
    "    print(f\"Embedding do Chunk {len(embedded_chunks)} gerado (tamanho: {len(embedding)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar os embeddings gerados\n",
    "print(\"\\nEmbeddings gerados (mostrando apenas os primeiros 5 elementos de cada):\")\n",
    "for i, embed in enumerate(embedded_chunks):\n",
    "    print(f\"Embedding {i+1}: {embed[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nNúmero de elementos em cada embedding: {len(embedded_chunks[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    return dot(vec1, vec2) / (norm(vec1) * norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSimilaridades entre todos os chunks:\")\n",
    "similarities = []\n",
    "for i in range(len(embedded_chunks)):\n",
    "    for j in range(i + 1, len(embedded_chunks)):\n",
    "        similarity = cosine_similarity(embedded_chunks[i], embedded_chunks[j])\n",
    "        similarities.append((i, j, similarity))\n",
    "        print(f\"Similaridade entre o chunk {i+1} e o chunk {j+1}: {similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_chunks_array = array(embedded_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(embedded_chunks_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(pca_result[:, 0], pca_result[:, 1], c='blue', edgecolor='k', s=50)\n",
    "for i, chunk in enumerate(chunks):\n",
    "    plt.text(pca_result[i, 0], pca_result[i, 1], f'Chunk {i+1}', fontsize=12)\n",
    "for (i, j, similarity) in similarities:\n",
    "    plt.plot([pca_result[i, 0], pca_result[j, 0]], [pca_result[i, 1], pca_result[j, 1]], 'k--', alpha=similarity)\n",
    "    mid_x = (pca_result[i, 0] + pca_result[j, 0]) / 2\n",
    "    mid_y = (pca_result[i, 1] + pca_result[j, 1]) / 2\n",
    "    plt.text(mid_x, mid_y, f'{similarity:.2f}', fontsize=8, color='green')\n",
    "plt.title('Visualização dos Embeddings com PCA')\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=2, max_iter=300)\n",
    "tsne_result = tsne.fit_transform(embedded_chunks_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c='red', edgecolor='k', s=50)\n",
    "for i, chunk in enumerate(chunks):\n",
    "    plt.text(tsne_result[i, 0], tsne_result[i, 1], f'Chunk {i+1}', fontsize=12)\n",
    "for (i, j, similarity) in similarities:\n",
    "    plt.plot([tsne_result[i, 0], tsne_result[j, 0]], [tsne_result[i, 1], tsne_result[j, 1]], 'k--', alpha=similarity)\n",
    "    mid_x = (tsne_result[i, 0] + tsne_result[j, 0]) / 2\n",
    "    mid_y = (tsne_result[i, 1] + tsne_result[j, 1]) / 2\n",
    "    plt.text(mid_x, mid_y, f'{similarity:.2f}', fontsize=8, color='green')\n",
    "plt.title('Visualização dos Embeddings com t-SNE')\n",
    "plt.xlabel('Dimensão 1')\n",
    "plt.ylabel('Dimensão 2')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
