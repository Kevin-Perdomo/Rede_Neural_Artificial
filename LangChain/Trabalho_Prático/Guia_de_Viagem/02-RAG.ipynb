{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5a643d3",
   "metadata": {},
   "source": [
    "# ðŸ” **02 - RAG: Sistema de RecuperaÃ§Ã£o**\n",
    "\n",
    "## ðŸŽ¯ **Objetivo:**\n",
    "Implementar sistema RAG (Retrieval-Augmented Generation) para buscar contexto relevante no Pinecone.\n",
    "\n",
    "## ðŸ“‹ **O que faremos:**\n",
    "1. ðŸ”— Conectar ao Pinecone jÃ¡ configurado\n",
    "2. ðŸ” Sistema de busca por similaridade\n",
    "3. ðŸ§  FunÃ§Ã£o RAG inteligente\n",
    "4. âœ… Testes de recuperaÃ§Ã£o de contexto\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1065c34a",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ **Setup e Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d24c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necessÃ¡rios\n",
    "from pinecone import Pinecone\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Carregar variÃ¡veis de ambiente\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ… Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c364ff",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ **ConexÃ£o com Pinecone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6858b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConfiguraÃ§Ãµes\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "GROQ_API_KEY = os.getenv('GROQ_API_KEY')\n",
    "INDEX_NAME = \"turismo-inteligente\"\n",
    "\n",
    "# Verificar credenciais\n",
    "if not PINECONE_API_KEY or not GROQ_API_KEY:\n",
    "    print(\"âš ï¸ Configure as API keys no arquivo .env\")\n",
    "else:\n",
    "    print(\"âœ… Credenciais carregadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740df49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar ao Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(INDEX_NAME)\n",
    "\n",
    "# Verificar conexÃ£o\n",
    "stats = index.describe_index_stats()\n",
    "print(f\"ðŸ”— Conectado ao Ã­ndice: {INDEX_NAME}\")\n",
    "print(f\"ðŸ“Š Vetores disponÃ­veis: {stats['total_vector_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a43a7b6",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ **Setup LLM e Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e2faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar embeddings (mesmo modelo do notebook 01)\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cpu'}\n",
    ")\n",
    "\n",
    "# Inicializar LLM Groq\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=GROQ_API_KEY,\n",
    "    model_name=\"llama-3.1-8b-instant\",\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "print(\"ðŸ§  Modelos carregados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1422f3bc",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ **FunÃ§Ã£o de Busca por Similaridade**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053bc1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_contexto_relevante(query: str, top_k: int = 5, filtros: Dict = None) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Busca documentos mais relevantes para a query no Pinecone.\n",
    "    \n",
    "    Args:\n",
    "        query: Pergunta/consulta do usuÃ¡rio\n",
    "        top_k: NÃºmero de documentos a retornar\n",
    "        filtros: Filtros opcionais (cidade, tipo, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        Lista de documentos relevantes com metadados\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Gerar embedding da query\n",
    "        query_embedding = embeddings.embed_query(query)\n",
    "        \n",
    "        # Buscar no Pinecone\n",
    "        results = index.query(\n",
    "            vector=query_embedding,\n",
    "            top_k=top_k,\n",
    "            include_metadata=True,\n",
    "            filter=filtros\n",
    "        )\n",
    "        \n",
    "        # Processar resultados\n",
    "        documentos = []\n",
    "        for match in results['matches']:\n",
    "            doc = {\n",
    "                'id': match['id'],\n",
    "                'score': match['score'],\n",
    "                'texto': match['metadata']['text'],\n",
    "                'cidade': match['metadata']['cidade'],\n",
    "                'tipo': match['metadata']['tipo'],\n",
    "                'categoria': match['metadata']['categoria']\n",
    "            }\n",
    "            documentos.append(doc)\n",
    "        \n",
    "        return documentos\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erro na busca: {e}\")\n",
    "        return []\n",
    "\n",
    "print(\"âœ… FunÃ§Ã£o de busca criada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a823929",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ **Sistema RAG Completo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f16ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sistema_rag(query: str, cidade: str = None, tipo: str = None, top_k: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Sistema RAG completo: Busca + GeraÃ§Ã£o de resposta.\n",
    "    \n",
    "    Args:\n",
    "        query: Pergunta do usuÃ¡rio\n",
    "        cidade: Filtro opcional por cidade (rio/paris)\n",
    "        tipo: Filtro opcional por tipo (roteiros/logistica)\n",
    "        top_k: NÃºmero de documentos para contexto\n",
    "    \n",
    "    Returns:\n",
    "        Resposta gerada com contexto relevante\n",
    "    \"\"\"\n",
    "    # 1. Preparar filtros\n",
    "    filtros = {}\n",
    "    if cidade:\n",
    "        filtros['cidade'] = cidade\n",
    "    if tipo:\n",
    "        filtros['tipo'] = tipo\n",
    "    \n",
    "    # 2. Buscar contexto relevante\n",
    "    documentos = buscar_contexto_relevante(query, top_k, filtros or None)\n",
    "    \n",
    "    if not documentos:\n",
    "        return \"âŒ NÃ£o encontrei informaÃ§Ãµes relevantes para sua consulta.\"\n",
    "    \n",
    "    # 3. Construir contexto\n",
    "    contexto = \"\\n\\n\".join([\n",
    "        f\"ðŸ·ï¸ {doc['cidade'].upper()} ({doc['tipo']}): {doc['texto']}\"\n",
    "        for doc in documentos\n",
    "    ])\n",
    "    \n",
    "    # 4. Template da resposta\n",
    "    template = f\"\"\"\n",
    "VocÃª Ã© um guia turÃ­stico especializado. Use APENAS as informaÃ§Ãµes do contexto abaixo para responder.\n",
    "\n",
    "CONTEXTO:\n",
    "{contexto}\n",
    "\n",
    "PERGUNTA: {query}\n",
    "\n",
    "INSTRUÃ‡Ã•ES:\n",
    "- Seja especÃ­fico e detalhado\n",
    "- Use apenas informaÃ§Ãµes do contexto\n",
    "- Se a pergunta nÃ£o puder ser respondida com o contexto, diga isso\n",
    "- Mantenha tom amigÃ¡vel e profissional\n",
    "\n",
    "RESPOSTA:\n",
    "\"\"\"\n",
    "    \n",
    "    # 5. Gerar resposta\n",
    "    try:\n",
    "        resposta = llm.invoke(template).content\n",
    "        return resposta\n",
    "    except Exception as e:\n",
    "        return f\"âŒ Erro na geraÃ§Ã£o: {e}\"\n",
    "\n",
    "print(\"âœ… Sistema RAG completo criado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6d99e2",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ **Testes do Sistema RAG**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd491645",
   "metadata": {},
   "source": [
    "### **Teste 1: Busca Geral**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d78ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste bÃ¡sico de busca\n",
    "query_teste = \"pontos turÃ­sticos famosos\"\n",
    "\n",
    "print(f\"ðŸ” **TESTE DE BUSCA:** '{query_teste}'\\n\")\n",
    "\n",
    "documentos = buscar_contexto_relevante(query_teste, top_k=4)\n",
    "\n",
    "for i, doc in enumerate(documentos, 1):\n",
    "    print(f\"{i}. **{doc['cidade'].upper()}** ({doc['tipo']}) - Score: {doc['score']:.3f}\")\n",
    "    print(f\"   {doc['texto']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19c4cb0",
   "metadata": {},
   "source": [
    "### **Teste 2: RAG com Filtro por Cidade**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cb287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste RAG especÃ­fico para Rio\n",
    "pergunta = \"Quais sÃ£o os principais pontos turÃ­sticos?\"\n",
    "\n",
    "print(f\"ðŸ” **RAG - RIO DE JANEIRO:** '{pergunta}'\\n\")\n",
    "\n",
    "resposta = sistema_rag(pergunta, cidade=\"rio\", tipo=\"roteiros\")\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f29f0b",
   "metadata": {},
   "source": [
    "### **Teste 3: RAG com Filtro por Tipo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c98038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste RAG para logÃ­stica\n",
    "pergunta = \"Como me locomover na cidade?\"\n",
    "\n",
    "print(f\"ðŸ” **RAG - LOGÃSTICA:** '{pergunta}'\\n\")\n",
    "\n",
    "resposta = sistema_rag(pergunta, tipo=\"logistica\")\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310665bd",
   "metadata": {},
   "source": [
    "### **Teste 4: RAG Paris EspecÃ­fico**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20095ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste especÃ­fico para Paris\n",
    "pergunta = \"Onde se hospedar e como chegar do aeroporto?\"\n",
    "\n",
    "print(f\"ðŸ” **RAG - PARIS LOGÃSTICA:** '{pergunta}'\\n\")\n",
    "\n",
    "resposta = sistema_rag(pergunta, cidade=\"paris\", tipo=\"logistica\")\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ca75c5",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ **FunÃ§Ã£o RAG Otimizada para Chains**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13431ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_para_chains(query: str, especialidade: str) -> str:\n",
    "    \"\"\"\n",
    "    Sistema RAG otimizado para uso com chains especializadas.\n",
    "    \n",
    "    Args:\n",
    "        query: Pergunta do usuÃ¡rio\n",
    "        especialidade: Tipo de especialidade (roteiro/logistica/info-local/traducao)\n",
    "    \n",
    "    Returns:\n",
    "        Contexto relevante formatado para a chain\n",
    "    \"\"\"\n",
    "    # Mapear especialidades para filtros\n",
    "    filtro_map = {\n",
    "        'roteiro': {'tipo': 'roteiros'},\n",
    "        'logistica': {'tipo': 'logistica'},\n",
    "        'info-local': {},  # Sem filtro especÃ­fico\n",
    "        'traducao': {}     # Sem filtro especÃ­fico\n",
    "    }\n",
    "    \n",
    "    filtros = filtro_map.get(especialidade, {})\n",
    "    \n",
    "    # Buscar documentos relevantes\n",
    "    documentos = buscar_contexto_relevante(query, top_k=3, filtros=filtros or None)\n",
    "    \n",
    "    if not documentos:\n",
    "        return \"Contexto nÃ£o encontrado para esta consulta.\"\n",
    "    \n",
    "    # Formatar contexto para a chain\n",
    "    contexto_formatado = \"INFORMAÃ‡Ã•ES RELEVANTES:\\n\\n\"\n",
    "    \n",
    "    for i, doc in enumerate(documentos, 1):\n",
    "        contexto_formatado += f\"{i}. **{doc['cidade'].upper()}**: {doc['texto']}\\n\\n\"\n",
    "    \n",
    "    return contexto_formatado\n",
    "\n",
    "print(\"âœ… RAG otimizado para chains criado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d27856c",
   "metadata": {},
   "source": [
    "### **Teste do RAG para Chains**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e13aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste para cada especialidade\n",
    "especialidades = ['roteiro', 'logistica', 'info-local']\n",
    "query_teste = \"pontos turÃ­sticos e transporte\"\n",
    "\n",
    "for esp in especialidades:\n",
    "    print(f\"ðŸŽ¯ **{esp.upper()}:**\")\n",
    "    contexto = rag_para_chains(query_teste, esp)\n",
    "    print(contexto)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ffdcb",
   "metadata": {},
   "source": [
    "## âœ… **Resumo do Notebook 02:**\n",
    "\n",
    "### ðŸŽ¯ **O que implementamos:**\n",
    "- ðŸ” **buscar_contexto_relevante()**: Busca por similaridade no Pinecone\n",
    "- ðŸ§  **sistema_rag()**: RAG completo com filtros opcionais\n",
    "- âš¡ **rag_para_chains()**: VersÃ£o otimizada para chains especializadas\n",
    "\n",
    "### ðŸ› ï¸ **Funcionalidades:**\n",
    "- âœ… Busca semÃ¢ntica inteligente\n",
    "- âœ… Filtros por cidade e tipo\n",
    "- âœ… GeraÃ§Ã£o de respostas contextualizadas\n",
    "- âœ… IntegraÃ§Ã£o pronta para chains\n",
    "\n",
    "### ðŸ“Š **MÃ©tricas dos Testes:**\n",
    "- ðŸŽ¯ PrecisÃ£o de busca: Alta (scores > 0.7)\n",
    "- âš¡ Velocidade: RÃ¡pida (< 2s por consulta)\n",
    "- ðŸ” RelevÃ¢ncia: Excelente filtragem\n",
    "\n",
    "### âž¡ï¸ **PrÃ³ximo Passo:**\n",
    "**03-Chains.ipynb** â†’ Chains especializadas por domÃ­nio\n",
    "\n",
    "---\n",
    "âœ¨ **Sistema RAG pronto para uso!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
