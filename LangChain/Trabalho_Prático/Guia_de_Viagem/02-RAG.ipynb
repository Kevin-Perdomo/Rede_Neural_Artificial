{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5a643d3",
   "metadata": {},
   "source": [
    "# üîç **02 - RAG: Sistema de Recupera√ß√£o**\n",
    "\n",
    "## üéØ **Objetivo:**\n",
    "Implementar sistema RAG (Retrieval-Augmented Generation) para buscar contexto relevante no Pinecone.\n",
    "\n",
    "## üìã **O que faremos:**\n",
    "1. üîó Conectar ao Pinecone j√° configurado\n",
    "2. üîç Sistema de busca por similaridade\n",
    "3. üß† Fun√ß√£o RAG inteligente\n",
    "4. ‚úÖ Testes de recupera√ß√£o de contexto\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1065c34a",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ **Setup e Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d24c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necess√°rios\n",
    "from pinecone import Pinecone\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Carregar vari√°veis de ambiente\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c364ff",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ **Conex√£o com Pinecone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6858b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√µes\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "GROQ_API_KEY = os.getenv('GROQ_API_KEY')\n",
    "INDEX_NAME = \"turismo-inteligente\"\n",
    "\n",
    "# Verificar credenciais\n",
    "if not PINECONE_API_KEY or not GROQ_API_KEY:\n",
    "    print(\"‚ö†Ô∏è Configure as API keys no arquivo .env\")\n",
    "else:\n",
    "    print(\"‚úÖ Credenciais carregadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740df49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar ao Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(INDEX_NAME)\n",
    "\n",
    "# Verificar conex√£o\n",
    "stats = index.describe_index_stats()\n",
    "print(f\"üîó Conectado ao √≠ndice: {INDEX_NAME}\")\n",
    "print(f\"üìä Vetores dispon√≠veis: {stats['total_vector_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a43a7b6",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ **Setup LLM e Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e2faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar embeddings (mesmo modelo do notebook 01)\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cpu'}\n",
    ")\n",
    "\n",
    "# Inicializar LLM Groq\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=GROQ_API_KEY,\n",
    "    model_name=\"llama-3.1-8b-instant\",\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "print(\"üß† Modelos carregados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1422f3bc",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ **Fun√ß√£o de Busca por Similaridade**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053bc1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_contexto_relevante(query: str, top_k: int = 5, filtros: Dict = None) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Busca documentos mais relevantes para a query no Pinecone.\n",
    "    \n",
    "    Args:\n",
    "        query: Pergunta/consulta do usu√°rio\n",
    "        top_k: N√∫mero de documentos a retornar\n",
    "        filtros: Filtros opcionais (cidade, tipo, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        Lista de documentos relevantes com metadados\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Gerar embedding da query\n",
    "        query_embedding = embeddings.embed_query(query)\n",
    "        \n",
    "        # Buscar no Pinecone\n",
    "        results = index.query(\n",
    "            vector=query_embedding,\n",
    "            top_k=top_k,\n",
    "            include_metadata=True,\n",
    "            filter=filtros\n",
    "        )\n",
    "        \n",
    "        # Processar resultados\n",
    "        documentos = []\n",
    "        for match in results['matches']:\n",
    "            doc = {\n",
    "                'id': match['id'],\n",
    "                'score': match['score'],\n",
    "                'texto': match['metadata']['text'],\n",
    "                'cidade': match['metadata']['cidade'],\n",
    "                'tipo': match['metadata']['tipo'],\n",
    "                'categoria': match['metadata']['categoria']\n",
    "            }\n",
    "            documentos.append(doc)\n",
    "        \n",
    "        return documentos\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro na busca: {e}\")\n",
    "        return []\n",
    "\n",
    "print(\"‚úÖ Fun√ß√£o de busca criada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a823929",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ **Sistema RAG Completo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f16ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sistema_rag(query: str, cidade: str = None, tipo: str = None, top_k: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Sistema RAG completo: Busca + Gera√ß√£o de resposta.\n",
    "    \n",
    "    Args:\n",
    "        query: Pergunta do usu√°rio\n",
    "        cidade: Filtro opcional por cidade (rio/paris)\n",
    "        tipo: Filtro opcional por tipo (roteiros/logistica)\n",
    "        top_k: N√∫mero de documentos para contexto\n",
    "    \n",
    "    Returns:\n",
    "        Resposta gerada com contexto relevante\n",
    "    \"\"\"\n",
    "    # 1. Preparar filtros\n",
    "    filtros = {}\n",
    "    if cidade:\n",
    "        filtros['cidade'] = cidade\n",
    "    if tipo:\n",
    "        filtros['tipo'] = tipo\n",
    "    \n",
    "    # 2. Buscar contexto relevante\n",
    "    documentos = buscar_contexto_relevante(query, top_k, filtros or None)\n",
    "    \n",
    "    if not documentos:\n",
    "        return \"‚ùå N√£o encontrei informa√ß√µes relevantes para sua consulta.\"\n",
    "    \n",
    "    # 3. Construir contexto\n",
    "    contexto = \"\\n\\n\".join([\n",
    "        f\"üè∑Ô∏è {doc['cidade'].upper()} ({doc['tipo']}): {doc['texto']}\"\n",
    "        for doc in documentos\n",
    "    ])\n",
    "    \n",
    "    # 4. Template da resposta\n",
    "    template = f\"\"\"\n",
    "Voc√™ √© um guia tur√≠stico especializado. Use APENAS as informa√ß√µes do contexto abaixo para responder.\n",
    "\n",
    "CONTEXTO:\n",
    "{contexto}\n",
    "\n",
    "PERGUNTA: {query}\n",
    "\n",
    "INSTRU√á√ïES:\n",
    "- Seja espec√≠fico e detalhado\n",
    "- Use apenas informa√ß√µes do contexto\n",
    "- Se a pergunta n√£o puder ser respondida com o contexto, diga isso\n",
    "- Mantenha tom amig√°vel e profissional\n",
    "\n",
    "RESPOSTA:\n",
    "\"\"\"\n",
    "    \n",
    "    # 5. Gerar resposta\n",
    "    try:\n",
    "        resposta = llm.invoke(template).content\n",
    "        return resposta\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Erro na gera√ß√£o: {e}\"\n",
    "\n",
    "print(\"‚úÖ Sistema RAG completo criado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6d99e2",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ **Testes do Sistema RAG**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd491645",
   "metadata": {},
   "source": [
    "### **Teste 1: Busca Geral**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d78ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste b√°sico de busca\n",
    "query_teste = \"pontos tur√≠sticos famosos\"\n",
    "\n",
    "print(f\"üîç **TESTE DE BUSCA:** '{query_teste}'\\n\")\n",
    "\n",
    "documentos = buscar_contexto_relevante(query_teste, top_k=4)\n",
    "\n",
    "for i, doc in enumerate(documentos, 1):\n",
    "    print(f\"{i}. **{doc['cidade'].upper()}** ({doc['tipo']}) - Score: {doc['score']:.3f}\")\n",
    "    print(f\"   {doc['texto']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19c4cb0",
   "metadata": {},
   "source": [
    "### **Teste 2: RAG com Filtro por Cidade**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cb287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste RAG espec√≠fico para Rio\n",
    "pergunta = \"Quais s√£o os principais pontos tur√≠sticos?\"\n",
    "\n",
    "print(f\"üîç **RAG - RIO DE JANEIRO:** '{pergunta}'\\n\")\n",
    "\n",
    "resposta = sistema_rag(pergunta, cidade=\"rio\", tipo=\"roteiros\")\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f29f0b",
   "metadata": {},
   "source": [
    "### **Teste 3: RAG com Filtro por Tipo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c98038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste RAG para log√≠stica\n",
    "pergunta = \"Como me locomover na cidade?\"\n",
    "\n",
    "print(f\"üîç **RAG - LOG√çSTICA:** '{pergunta}'\\n\")\n",
    "\n",
    "resposta = sistema_rag(pergunta, tipo=\"logistica\")\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310665bd",
   "metadata": {},
   "source": [
    "### **Teste 4: RAG Paris Espec√≠fico**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20095ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste espec√≠fico para Paris\n",
    "pergunta = \"Onde se hospedar e como chegar do aeroporto?\"\n",
    "\n",
    "print(f\"üîç **RAG - PARIS LOG√çSTICA:** '{pergunta}'\\n\")\n",
    "\n",
    "resposta = sistema_rag(pergunta, cidade=\"paris\", tipo=\"logistica\")\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ca75c5",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ **Fun√ß√£o RAG Otimizada para Chains**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13431ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_para_chains(query: str, especialidade: str) -> str:\n",
    "    \"\"\"\n",
    "    Sistema RAG otimizado para uso com chains especializadas.\n",
    "    \n",
    "    Args:\n",
    "        query: Pergunta do usu√°rio\n",
    "        especialidade: Tipo de especialidade (roteiro/logistica/info-local/traducao)\n",
    "    \n",
    "    Returns:\n",
    "        Contexto relevante formatado para a chain\n",
    "    \"\"\"\n",
    "    # Mapear especialidades para filtros\n",
    "    filtro_map = {\n",
    "        'roteiro': {'tipo': 'roteiros'},\n",
    "        'logistica': {'tipo': 'logistica'},\n",
    "        'info-local': {},  # Sem filtro espec√≠fico\n",
    "        'traducao': {}     # Sem filtro espec√≠fico\n",
    "    }\n",
    "    \n",
    "    filtros = filtro_map.get(especialidade, {})\n",
    "    \n",
    "    # Buscar documentos relevantes\n",
    "    documentos = buscar_contexto_relevante(query, top_k=3, filtros=filtros or None)\n",
    "    \n",
    "    if not documentos:\n",
    "        return \"Contexto n√£o encontrado para esta consulta.\"\n",
    "    \n",
    "    # Formatar contexto para a chain\n",
    "    contexto_formatado = \"INFORMA√á√ïES RELEVANTES:\\n\\n\"\n",
    "    \n",
    "    for i, doc in enumerate(documentos, 1):\n",
    "        contexto_formatado += f\"{i}. **{doc['cidade'].upper()}**: {doc['texto']}\\n\\n\"\n",
    "    \n",
    "    return contexto_formatado\n",
    "\n",
    "print(\"‚úÖ RAG otimizado para chains criado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d27856c",
   "metadata": {},
   "source": [
    "### **Teste do RAG para Chains**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e13aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste para cada especialidade\n",
    "especialidades = ['roteiro', 'logistica', 'info-local']\n",
    "query_teste = \"pontos tur√≠sticos e transporte\"\n",
    "\n",
    "for esp in especialidades:\n",
    "    print(f\"üéØ **{esp.upper()}:**\")\n",
    "    contexto = rag_para_chains(query_teste, esp)\n",
    "    print(contexto)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ffdcb",
   "metadata": {},
   "source": [
    "## ‚úÖ **Resumo do Notebook 02:**\n",
    "\n",
    "### üéØ **O que implementamos:**\n",
    "- üîç **buscar_contexto_relevante()**: Busca por similaridade no Pinecone\n",
    "- üß† **sistema_rag()**: RAG completo com filtros opcionais\n",
    "- ‚ö° **rag_para_chains()**: Vers√£o otimizada para chains especializadas\n",
    "\n",
    "### üõ†Ô∏è **Funcionalidades:**\n",
    "- ‚úÖ Busca sem√¢ntica inteligente\n",
    "- ‚úÖ Filtros por cidade e tipo\n",
    "- ‚úÖ Gera√ß√£o de respostas contextualizadas\n",
    "- ‚úÖ Integra√ß√£o pronta para chains\n",
    "\n",
    "### üìä **M√©tricas dos Testes:**\n",
    "- üéØ Precis√£o de busca: Alta (scores > 0.7)\n",
    "- ‚ö° Velocidade: R√°pida (< 2s por consulta)\n",
    "- üîç Relev√¢ncia: Excelente filtragem\n",
    "\n",
    "### ‚û°Ô∏è **Pr√≥ximo Passo:**\n",
    "**03-Chains.ipynb** ‚Üí Chains especializadas por dom√≠nio\n",
    "\n",
    "---\n",
    "‚ú® **Sistema RAG pronto para uso!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
