{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80046a53",
   "metadata": {},
   "source": [
    "# ğŸ“Œ **01 - Pinecone: Base Vetorial**\n",
    "\n",
    "## ğŸ¯ **Objetivo:**\n",
    "Configurar e popular o Pinecone com dados turÃ­sticos para Rio e Paris.\n",
    "\n",
    "## ğŸ“‹ **O que faremos:**\n",
    "1. âš™ï¸ Setup do Pinecone\n",
    "2. ğŸ“Š CriaÃ§Ã£o do Ã­ndice vetorial  \n",
    "3. ğŸ“ IndexaÃ§Ã£o dos dados turÃ­sticos\n",
    "4. âœ… Testes de conectividade\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03ecd1e",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ **Setup e ConfiguraÃ§Ã£o**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c08f747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bibliotecas importadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Imports necessÃ¡rios\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "# Carregar variÃ¡veis de ambiente\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ… Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd07d3",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ **ConfiguraÃ§Ã£o do Pinecone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afb4c926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Credenciais carregadas!\n"
     ]
    }
   ],
   "source": [
    "# ConfiguraÃ§Ã£o das credenciais\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "PINECONE_ENVIRONMENT = os.getenv('PINECONE_ENVIRONMENT', 'us-east-1')\n",
    "INDEX_NAME = \"turismo-inteligente\"\n",
    "\n",
    "if not PINECONE_API_KEY:\n",
    "    print(\"âš ï¸ Configure PINECONE_API_KEY no arquivo .env\")\n",
    "else:\n",
    "    print(\"âœ… Credenciais carregadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ebf47d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Ãndices existentes:\n",
      "\n",
      "====================\n",
      " [] guia-viagem\n",
      "====================\n",
      " [] ia-na-pratica\n",
      "====================\n",
      " [] turismo-inteligente\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "# Inicializar cliente Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Verificar Ã­ndices existentes\n",
    "print(\"ğŸ“‹ Ãndices existentes:\")\n",
    "print()\n",
    "print(\"=\" * 20)\n",
    "\n",
    "for index in pc.list_indexes().names():\n",
    "    print(f\" [] {index}\")\n",
    "    print(\"=\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b75be8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ãndice 'turismo-inteligente' jÃ¡ existe!\n",
      "ğŸ”— Conectado ao Ã­ndice: turismo-inteligente\n"
     ]
    }
   ],
   "source": [
    "# Criar Ã­ndice se nÃ£o existir\n",
    "if INDEX_NAME not in pc.list_indexes().names():\n",
    "    print(f\"ğŸ”¨ Criando Ã­ndice '{INDEX_NAME}'...\")\n",
    "    \n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=384,  # Para sentence-transformers/all-MiniLM-L6-v2\n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region=PINECONE_ENVIRONMENT\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Aguardar inicializaÃ§Ã£o\n",
    "    while not pc.describe_index(INDEX_NAME).status['ready']:\n",
    "        time.sleep(1)\n",
    "        print(\"â³ Aguardando inicializaÃ§Ã£o...\")\n",
    "    \n",
    "    print(\"âœ… Ãndice criado com sucesso!\")\n",
    "else:\n",
    "    print(f\"âœ… Ãndice '{INDEX_NAME}' jÃ¡ existe!\")\n",
    "\n",
    "# Conectar ao Ã­ndice\n",
    "index = pc.Index(INDEX_NAME)\n",
    "print(f\"ğŸ”— Conectado ao Ã­ndice: {INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9f4271",
   "metadata": {},
   "source": [
    "## ğŸ—‘ï¸ **Limpeza de Ãndices (Opcional)**\n",
    "\n",
    "âš ï¸ **ATENÃ‡ÃƒO:** CÃ³digo de seguranÃ§a para remoÃ§Ã£o de Ã­ndices. Use apenas quando necessÃ¡rio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c66eccd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”’ CÃ³digo de limpeza disponÃ­vel (comentado por seguranÃ§a)\n",
      "ğŸ“ ANTES DE USAR: Modifique os nomes dos Ã­ndices nas variÃ¡veis acima\n",
      "ğŸ¯ Depois descomente apenas a opÃ§Ã£o que precisar\n"
     ]
    }
   ],
   "source": [
    "# ğŸš¨ CÃ“DIGO DE LIMPEZA - DESCOMENTE APENAS QUANDO NECESSÃRIO ğŸš¨\n",
    "\n",
    "# OpÃ§Ã£o 1: Apagar Ã­ndice especÃ­fico por nome\n",
    "# âš ï¸ CONFIGURE O NOME DO ÃNDICE AQUI ANTES DE DESCOMENTAR:\n",
    "index_para_apagar = \"rag-musculacao\"  # â† MODIFIQUE ESTE NOME CONFORME NECESSÃRIO\n",
    "\n",
    "# if index_para_apagar in pc.list_indexes().names():\n",
    "#     print(f\"ğŸ—‘ï¸ Apagando Ã­ndice '{index_para_apagar}'...\")\n",
    "#     pc.delete_index(index_para_apagar)\n",
    "#     print(f\"âœ… Ãndice '{index_para_apagar}' removido com sucesso!\")\n",
    "# else:\n",
    "#     print(f\"âš ï¸ Ãndice '{index_para_apagar}' nÃ£o existe.\")\n",
    "#     print(\"ğŸ“‹ Ãndices disponÃ­veis:\", list(pc.list_indexes().names()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# OpÃ§Ã£o 2: Apagar TODOS os Ã­ndices da conta (MUITO PERIGOSO!)\n",
    "# CUIDADO: Isso apagarÃ¡ TODOS os seus Ã­ndices Pinecone!\n",
    "\n",
    "# print(\"ğŸš¨ ATENÃ‡ÃƒO: Apagando TODOS os Ã­ndices...\")\n",
    "# indices = pc.list_indexes().names()\n",
    "\n",
    "# if not indices:\n",
    "#     print(\"âœ… Nenhum Ã­ndice encontrado.\")\n",
    "# else:\n",
    "#     for index_name in indices:\n",
    "#         print(f\"ğŸ—‘ï¸ Apagando: {index_name}\")\n",
    "#         pc.delete_index(index_name)\n",
    "    \n",
    "#     print(f\"ğŸ’€ TODOS os {len(indices)} Ã­ndices foram removidos!\")\n",
    "\n",
    "\n",
    "print(\"ğŸ”’ CÃ³digo de limpeza disponÃ­vel (comentado por seguranÃ§a)\")\n",
    "print(\"ğŸ“ ANTES DE USAR: Modifique os nomes dos Ã­ndices nas variÃ¡veis acima\")\n",
    "print(\"ğŸ¯ Depois descomente apenas a opÃ§Ã£o que precisar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348f4456",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ **Dados TurÃ­sticos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d328fc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š **BASE DE CONHECIMENTO CARREGADA:**\n",
      "   ğŸ·ï¸ RIO - ROTEIROS: 5 documentos\n",
      "   ğŸ·ï¸ RIO - LOGÃSTICA: 6 documentos\n",
      "   ğŸ·ï¸ PARIS - ROTEIROS: 5 documentos\n",
      "   ğŸ·ï¸ PARIS - LOGÃSTICA: 5 documentos\n",
      "\n",
      "ğŸ“Š Total de documentos: 21\n",
      "âœ… **Dados carregados de arquivo externo: base_conhecimento.txt**\n"
     ]
    }
   ],
   "source": [
    "def carregar_base_conhecimento(arquivo_path: str = \"base_conhecimento.txt\") -> dict:\n",
    "    \"\"\"\n",
    "    Carrega a base de conhecimento do arquivo txt e organiza em dicionÃ¡rio.\n",
    "    \n",
    "    Returns:\n",
    "        DicionÃ¡rio com dados organizados por categoria\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(arquivo_path, 'r', encoding='utf-8') as file:\n",
    "            conteudo = file.read()\n",
    "        \n",
    "        dados = {\n",
    "            \"rio_roteiros\": [],\n",
    "            \"rio_logistica\": [],\n",
    "            \"paris_roteiros\": [],\n",
    "            \"paris_logistica\": []\n",
    "        }\n",
    "        \n",
    "        linhas = conteudo.split('\\n')\n",
    "        secao_atual = None\n",
    "        \n",
    "        for linha in linhas:\n",
    "            linha = linha.strip()\n",
    "            if not linha or linha.startswith('#'):\n",
    "                continue\n",
    "                \n",
    "            # Identificar seÃ§Ãµes (com ou sem ##)\n",
    "            if 'ROTEIROS - RIO' in linha:\n",
    "                secao_atual = \"rio_roteiros\"\n",
    "                continue\n",
    "            elif 'LOGÃSTICA - RIO' in linha:\n",
    "                secao_atual = \"rio_logistica\"\n",
    "                continue\n",
    "            elif 'ROTEIROS - PARIS' in linha:\n",
    "                secao_atual = \"paris_roteiros\"\n",
    "                continue\n",
    "            elif 'LOGÃSTICA - PARIS' in linha:\n",
    "                secao_atual = \"paris_logistica\"\n",
    "                continue\n",
    "            elif secao_atual and ':' in linha and not linha.startswith('#'):\n",
    "                # Adicionar linha de dados Ã  seÃ§Ã£o atual (sem chunking aqui)\n",
    "                dados[secao_atual].append(linha)\n",
    "        \n",
    "        return dados\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"âš ï¸ Arquivo base_conhecimento.txt nÃ£o encontrado. Usando dados padrÃ£o.\")\n",
    "        # Fallback com dados bÃ¡sicos\n",
    "        return {\n",
    "            \"rio_roteiros\": [\n",
    "                \"Cristo Redentor: Uma das Sete Maravilhas do Mundo Moderno.\",\n",
    "                \"PÃ£o de AÃ§Ãºcar: Bondinho famoso com vista panorÃ¢mica.\"\n",
    "            ],\n",
    "            \"rio_logistica\": [\n",
    "                \"Aeroporto GaleÃ£o: Principal aeroporto internacional.\",\n",
    "                \"Metro Rio: Conecta principais pontos turÃ­sticos.\"\n",
    "            ],\n",
    "            \"paris_roteiros\": [\n",
    "                \"Torre Eiffel: SÃ­mbolo de Paris, 324m de altura.\",\n",
    "                \"Museu do Louvre: Maior museu do mundo.\"\n",
    "            ],\n",
    "            \"paris_logistica\": [\n",
    "                \"Charles de Gaulle: Principal aeroporto.\",\n",
    "                \"Metro Paris: 14 linhas disponÃ­veis.\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "# Carregar base de conhecimento do arquivo externo\n",
    "dados_turismo = carregar_base_conhecimento()\n",
    "\n",
    "print(\"ğŸ“š **BASE DE CONHECIMENTO CARREGADA:**\")\n",
    "for categoria, docs in dados_turismo.items():\n",
    "    cidade = \"RIO\" if \"rio\" in categoria else \"PARIS\"\n",
    "    tipo = \"ROTEIROS\" if \"roteiros\" in categoria else \"LOGÃSTICA\"\n",
    "    print(f\"   ğŸ·ï¸ {cidade} - {tipo}: {len(docs)} documentos\")\n",
    "\n",
    "total_docs = sum(len(docs) for docs in dados_turismo.values())\n",
    "print(f\"\\nğŸ“Š Total de documentos: {total_docs}\")\n",
    "print(\"âœ… **Dados carregados de arquivo externo: base_conhecimento.txt**\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c797c571",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ **Chunking dos Dados**\n",
    "\n",
    "âš™ï¸ **Processamento:** Dividir documentos grandes em chunks menores para melhor performance dos embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d15cdf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ **APLICANDO CHUNKING NOS DADOS...**\n",
      "\n",
      "ğŸ“ **RIO - ROTEIROS:**\n",
      "   ğŸ“„ Doc 1: Cristo Redentor: Uma das Sete Maravilhas do Mundo ...\n",
      "      âœ 1 chunk(s) gerado(s)\n",
      "        1. [83 chars] Cristo Redentor: Uma das Sete Maravilhas do Mundo Moderno, localizado no Corcovado.\n",
      "   ğŸ“„ Doc 2: PÃ£o de AÃ§Ãºcar: Bondinho famoso com vista panorÃ¢mic...\n",
      "      âœ 1 chunk(s) gerado(s)\n",
      "        1. [71 chars] PÃ£o de AÃ§Ãºcar: Bondinho famoso com vista panorÃ¢mica da cidade e praias.\n",
      "   ğŸ“„ Doc 3: Praia de Copacabana: 4km de areia branca, calÃ§adÃ£o...\n",
      "      âœ 1 chunk(s) gerado(s)\n",
      "        1. [75 chars] Praia de Copacabana: 4km de areia branca, calÃ§adÃ£o famoso, hotÃ©is luxuosos.\n",
      "   ğŸ“„ Doc 4: Praia de Ipanema: Bairro sofisticado, praia das ce...\n",
      "      âœ 1 chunk(s) gerado(s)\n",
      "        1. [86 chars] Praia de Ipanema: Bairro sofisticado, praia das celebridades, pÃ´r do sol inesquecÃ­vel.\n",
      "   ğŸ“„ Doc 5: Santa Teresa: Bairro boÃªmio, casarÃµes coloniais, a...\n",
      "      âœ 1 chunk(s) gerado(s)\n",
      "        1. [69 chars] Santa Teresa: Bairro boÃªmio, casarÃµes coloniais, ateliÃªs de artistas.\n",
      "\n",
      "ğŸ“ **RIO - LOGÃSTICA:**\n",
      "   ğŸ“„ Doc 1: Aeroporto GaleÃ£o: Principal aeroporto internaciona...\n",
      "      âœ 1 chunk(s) gerado(s)\n",
      "        1. [68 chars] Aeroporto GaleÃ£o: Principal aeroporto internacional, 20km do centro.\n",
      "   ğŸ“„ Doc 2: Aeroporto Santos Dumont: Aeroporto domÃ©stico no ce...\n",
      "      âœ 1 chunk(s) gerado(s)\n",
      "        1. [122 chars] Aeroporto Santos Dumont: Aeroporto domÃ©stico no centro da cidade, voos nacionais, vista privilegiada da BaÃ­a de Guanabara.\n",
      "   ğŸ“„ Doc 3: Metro Rio: Linhas 1, 2 e 4 conectam principais pon...\n",
      "      âœ 1 chunk(s) gerado(s)\n",
      "        1. [65 chars] Metro Rio: Linhas 1, 2 e 4 conectam principais pontos turÃ­sticos.\n",
      "   ğŸ“„ Doc 4: Uber/99: DisponÃ­vel 24h, mais seguro que tÃ¡xi comu...\n",
      "      âœ 1 chunk(s) gerado(s)\n",
      "        1. [52 chars] Uber/99: DisponÃ­vel 24h, mais seguro que tÃ¡xi comum.\n",
      "   ğŸ“„ Doc 5: BRT: Ã”nibus rÃ¡pido conecta Barra da Tijuca ao cent...\n",
      "      âœ 1 chunk(s) gerado(s)\n",
      "        1. [53 chars] BRT: Ã”nibus rÃ¡pido conecta Barra da Tijuca ao centro.\n",
      "   ğŸ“„ Doc 6: Hospedagem Copacabana: HotÃ©is de todas as categori...\n",
      "      âœ 1 chunk(s) gerado(s)\n",
      "        1. [61 chars] Hospedagem Copacabana: HotÃ©is de todas as categorias na orla.\n",
      "\n",
      "ğŸ“ **PARIS - ROTEIROS:**\n",
      "   ğŸ“„ Doc 1: Torre Eiffel: SÃ­mbolo de Paris, 324m de altura, il...\n",
      "      âœ 1 chunk(s) gerado(s)\n",
      "        1. [79 chars] Torre Eiffel: SÃ­mbolo de Paris, 324m de altura, iluminaÃ§Ã£o noturna espetacular.\n",
      "   ğŸ“„ Doc 2: Museu do Louvre: Maior museu do mundo, Mona Lisa, ...\n",
      "      âœ 1 chunk(s) gerado(s)\n",
      "        1. [64 chars] Museu do Louvre: Maior museu do mundo, Mona Lisa, arte clÃ¡ssica.\n",
      "   ğŸ“„ Doc 3: Notre-Dame: Catedral gÃ³tica, arquitetura medieval,...\n",
      "      âœ 1 chunk(s) gerado(s)\n",
      "        1. [66 chars] Notre-Dame: Catedral gÃ³tica, arquitetura medieval, Ile de la CitÃ©.\n",
      "   ğŸ“„ Doc 4: Champs-Ã‰lysÃ©es: Avenida mais famosa, compras, cafÃ©...\n",
      "      âœ 1 chunk(s) gerado(s)\n",
      "        1. [69 chars] Champs-Ã‰lysÃ©es: Avenida mais famosa, compras, cafÃ©s, Arc de Triomphe.\n",
      "   ğŸ“„ Doc 5: Montmartre: Bairro artÃ­stico, SacrÃ©-CÅ“ur, cabarÃ©s,...\n",
      "      âœ 1 chunk(s) gerado(s)\n",
      "        1. [68 chars] Montmartre: Bairro artÃ­stico, SacrÃ©-CÅ“ur, cabarÃ©s, vista panorÃ¢mica.\n",
      "\n",
      "ğŸ“ **PARIS - LOGÃSTICA:**\n",
      "   ğŸ“„ Doc 1: Charles de Gaulle: Principal aeroporto, RER B cone...\n",
      "      âœ 1 chunk(s) gerado(s)\n",
      "        1. [73 chars] Charles de Gaulle: Principal aeroporto, RER B conecta ao centro em 45min.\n",
      "   ğŸ“„ Doc 2: Metro Paris: 14 linhas, passe Navigo, funciona atÃ©...\n",
      "      âœ 1 chunk(s) gerado(s)\n",
      "        1. [76 chars] Metro Paris: 14 linhas, passe Navigo, funciona atÃ© 1h15 (2h15 sexta/sÃ¡bado).\n",
      "   ğŸ“„ Doc 3: Uber/Taxi: DisponÃ­vel, mas metro Ã© mais rÃ¡pido no ...\n",
      "      âœ 1 chunk(s) gerado(s)\n",
      "        1. [57 chars] Uber/Taxi: DisponÃ­vel, mas metro Ã© mais rÃ¡pido no centro.\n",
      "   ğŸ“„ Doc 4: Hotel Le Marais: Bairro histÃ³rico, walking distanc...\n",
      "      âœ 1 chunk(s) gerado(s)\n",
      "        1. [64 chars] Hotel Le Marais: Bairro histÃ³rico, walking distance de atraÃ§Ãµes.\n",
      "   ğŸ“„ Doc 5: Velib: Sistema de bikes compartilhadas, ideal para...\n",
      "      âœ 1 chunk(s) gerado(s)\n",
      "        1. [69 chars] Velib: Sistema de bikes compartilhadas, ideal para curtas distÃ¢ncias.\n",
      "\n",
      "ğŸ“Š **RESUMO DO CHUNKING:**\n",
      "   ğŸ“ˆ Total de chunks: 21\n",
      "   ğŸ“ Limite por chunk: 200 caracteres\n",
      "   ğŸ¯ EstratÃ©gia: sentenÃ§as â†’ vÃ­rgulas â†’ forÃ§a bruta\n",
      "âœ… **Chunking concluÃ­do com sucesso!**\n"
     ]
    }
   ],
   "source": [
    "def aplicar_chunking(texto: str, max_chars: int = 200) -> list:\n",
    "    \"\"\"\n",
    "    Aplica estratÃ©gia de chunking em um texto.\n",
    "    \n",
    "    Args:\n",
    "        texto: Texto para fazer chunking\n",
    "        max_chars: MÃ¡ximo de caracteres por chunk\n",
    "        \n",
    "    Returns:\n",
    "        Lista de chunks\n",
    "    \"\"\"\n",
    "    # Se o texto Ã© pequeno, retorna como estÃ¡\n",
    "    if len(texto) <= max_chars:\n",
    "        return [texto]\n",
    "    \n",
    "    chunks = []\n",
    "    \n",
    "    # EstratÃ©gia 1: Dividir por sentenÃ§as (ponto final)\n",
    "    sentences = texto.split('. ')\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        # Adicionar ponto final de volta (exceto na Ãºltima)\n",
    "        if sentence != sentences[-1]:\n",
    "            sentence += \".\"\n",
    "            \n",
    "        # Se adicionar esta sentenÃ§a ultrapassar o limite\n",
    "        if len(current_chunk + sentence) > max_chars and current_chunk:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence\n",
    "        else:\n",
    "            current_chunk += \" \" + sentence if current_chunk else sentence\n",
    "    \n",
    "    # Adicionar Ãºltimo chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    \n",
    "    # Se ainda houver chunks muito grandes, dividir por vÃ­rgula\n",
    "    final_chunks = []\n",
    "    for chunk in chunks:\n",
    "        if len(chunk) > max_chars:\n",
    "            # Dividir por vÃ­rgula\n",
    "            parts = chunk.split(', ')\n",
    "            temp_chunk = \"\"\n",
    "            \n",
    "            for part in parts:\n",
    "                if len(temp_chunk + part) > max_chars and temp_chunk:\n",
    "                    final_chunks.append(temp_chunk.strip())\n",
    "                    temp_chunk = part\n",
    "                else:\n",
    "                    temp_chunk += \", \" + part if temp_chunk else part\n",
    "                    \n",
    "            if temp_chunk:\n",
    "                final_chunks.append(temp_chunk.strip())\n",
    "        else:\n",
    "            final_chunks.append(chunk)\n",
    "    \n",
    "    return final_chunks if final_chunks else [texto]\n",
    "\n",
    "# Aplicar chunking nos dados carregados\n",
    "print(\"ğŸ”„ **APLICANDO CHUNKING NOS DADOS...**\\n\")\n",
    "\n",
    "dados_com_chunks = {}\n",
    "total_chunks = 0\n",
    "\n",
    "for categoria, documentos in dados_turismo.items():\n",
    "    cidade = \"RIO\" if \"rio\" in categoria else \"PARIS\"\n",
    "    tipo = \"ROTEIROS\" if \"roteiros\" in categoria else \"LOGÃSTICA\"\n",
    "    \n",
    "    print(f\"ğŸ“ **{cidade} - {tipo}:**\")\n",
    "    \n",
    "    chunks_categoria = []\n",
    "    \n",
    "    for i, doc in enumerate(documentos):\n",
    "        print(f\"   ğŸ“„ Doc {i+1}: {doc[:50]}...\")\n",
    "        \n",
    "        # Aplicar chunking\n",
    "        chunks = aplicar_chunking(doc, max_chars=200)\n",
    "        \n",
    "        print(f\"      âœ {len(chunks)} chunk(s) gerado(s)\")\n",
    "        for j, chunk in enumerate(chunks):\n",
    "            print(f\"        {j+1}. [{len(chunk)} chars] {chunk}\")\n",
    "            \n",
    "        chunks_categoria.extend(chunks)\n",
    "        total_chunks += len(chunks)\n",
    "    \n",
    "    dados_com_chunks[categoria] = chunks_categoria\n",
    "    print()\n",
    "\n",
    "print(f\"ğŸ“Š **RESUMO DO CHUNKING:**\")\n",
    "print(f\"   ğŸ“ˆ Total de chunks: {total_chunks}\")\n",
    "print(f\"   ğŸ“ Limite por chunk: 200 caracteres\")\n",
    "print(f\"   ğŸ¯ EstratÃ©gia: sentenÃ§as â†’ vÃ­rgulas â†’ forÃ§a bruta\")\n",
    "print(\"âœ… **Chunking concluÃ­do com sucesso!**\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b101cf08",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ **Setup dos Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a6e1a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  Modelo de embeddings carregado!\n",
      "ğŸ“ DimensÃ£o: 384\n"
     ]
    }
   ],
   "source": [
    "# Inicializar modelo de embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cpu'}\n",
    ")\n",
    "\n",
    "print(\"ğŸ§  Modelo de embeddings carregado!\")\n",
    "print(f\"ğŸ“ DimensÃ£o: {len(embeddings.embed_query('teste'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d670aa90",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ **IndexaÃ§Ã£o AutomÃ¡tica no Pinecone**\n",
    "\n",
    "ğŸ”„ **Sistema Simplificado:** Sempre limpa e reindexiza para garantir dados atualizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb427f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ Limpando dados existentes...\n",
      "âœ… Dados anteriores removidos!\n",
      "ğŸš€ Iniciando nova indexaÃ§Ã£o...\n",
      "ğŸ“ Preparado: rio_roteiros_0\n",
      "ğŸ“ Preparado: rio_roteiros_1\n",
      "ğŸ“ Preparado: rio_roteiros_2\n",
      "ğŸ“ Preparado: rio_roteiros_3\n",
      "ğŸ“ Preparado: rio_roteiros_4\n",
      "ğŸ“ Preparado: rio_logistica_0\n",
      "ğŸ“ Preparado: rio_logistica_1\n",
      "ğŸ“ Preparado: rio_logistica_2\n",
      "ğŸ“ Preparado: rio_logistica_3\n",
      "ğŸ“ Preparado: rio_logistica_4\n",
      "ğŸ“ Preparado: rio_logistica_5\n",
      "ğŸ“ Preparado: paris_roteiros_0\n",
      "ğŸ“ Preparado: paris_roteiros_1\n",
      "ğŸ“ Preparado: paris_roteiros_2\n",
      "ğŸ“ Preparado: paris_roteiros_3\n",
      "ğŸ“ Preparado: paris_roteiros_4\n",
      "ğŸ“ Preparado: paris_logistica_0\n",
      "ğŸ“ Preparado: paris_logistica_1\n",
      "ğŸ“ Preparado: paris_logistica_2\n",
      "ğŸ“ Preparado: paris_logistica_3\n",
      "ğŸ“ Preparado: paris_logistica_4\n",
      "ğŸ“¤ Inserindo 21 vetores...\n",
      "âœ… IndexaÃ§Ã£o completa!\n",
      "ğŸ¯ Sistema sempre atualizado com dados mais recentes!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”„ SISTEMA SIMPLES: Limpar e Reindexar SEMPRE\n",
    "print(\"ğŸ§¹ Limpando dados existentes...\")\n",
    "\n",
    "# Apagar todos os vetores do Ã­ndice\n",
    "index.delete(delete_all=True)\n",
    "print(\"âœ… Dados anteriores removidos!\")\n",
    "\n",
    "# Aguardar limpeza\n",
    "time.sleep(2)\n",
    "\n",
    "print(\"ğŸš€ Iniciando nova indexaÃ§Ã£o...\")\n",
    "\n",
    "vectors_to_upsert = []\n",
    "\n",
    "for categoria, documentos in dados_com_chunks.items():\n",
    "    for i, doc in enumerate(documentos):\n",
    "        # Gerar embedding\n",
    "        embedding = embeddings.embed_query(doc)\n",
    "        \n",
    "        # Criar ID Ãºnico\n",
    "        vector_id = f\"{categoria}_{i}\"\n",
    "        \n",
    "        # Preparar vetor com metadados\n",
    "        vector_data = {\n",
    "            \"id\": vector_id,\n",
    "            \"values\": embedding,\n",
    "            \"metadata\": {\n",
    "                \"text\": doc,\n",
    "                \"categoria\": categoria,\n",
    "                \"cidade\": \"rio\" if \"rio\" in categoria else \"paris\",\n",
    "                \"tipo\": \"roteiros\" if \"roteiros\" in categoria else \"logistica\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        vectors_to_upsert.append(vector_data)\n",
    "        print(f\"ğŸ“ Preparado: {vector_id}\")\n",
    "\n",
    "# Fazer upsert em lote\n",
    "print(f\"ğŸ“¤ Inserindo {len(vectors_to_upsert)} vetores...\")\n",
    "index.upsert(vectors=vectors_to_upsert)\n",
    "\n",
    "print(\"âœ… IndexaÃ§Ã£o completa!\")\n",
    "print(\"ğŸ¯ Sistema sempre atualizado com dados mais recentes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bc07b3",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ **Teste de Conectividade**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00120830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š **ESTATÃSTICAS DO ÃNDICE:**\n",
      "   ğŸ“ˆ Total de vetores: 0\n",
      "   ğŸ·ï¸ Namespaces: default\n",
      "   ğŸ’¾ DimensÃ£o: 384\n"
     ]
    }
   ],
   "source": [
    "# Aguardar propagaÃ§Ã£o dos dados\n",
    "time.sleep(2)\n",
    "\n",
    "# Verificar estatÃ­sticas finais\n",
    "stats = index.describe_index_stats()\n",
    "print(\"ğŸ“Š **ESTATÃSTICAS DO ÃNDICE:**\")\n",
    "print(f\"   ğŸ“ˆ Total de vetores: {stats['total_vector_count']}\")\n",
    "print(f\"   ğŸ·ï¸ Namespaces: {list(stats.get('namespaces', {}).keys()) if stats.get('namespaces') else 'default'}\")\n",
    "print(f\"   ğŸ’¾ DimensÃ£o: {stats.get('dimension', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71f83c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” **TESTE DE BUSCA:** 'pontos turÃ­sticos famosos'\n",
      "\n",
      "ğŸ“‹ **RESULTADOS:**\n"
     ]
    }
   ],
   "source": [
    "# Teste de busca simples\n",
    "query = \"pontos turÃ­sticos famosos\"\n",
    "query_embedding = embeddings.embed_query(query)\n",
    "\n",
    "# Buscar documentos similares\n",
    "results = index.query(\n",
    "    vector=query_embedding,\n",
    "    top_k=3,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "print(f\"ğŸ” **TESTE DE BUSCA:** '{query}'\")\n",
    "print(\"\\nğŸ“‹ **RESULTADOS:**\")\n",
    "for i, match in enumerate(results['matches'], 1):\n",
    "    score = match['score']\n",
    "    text = match['metadata']['text']\n",
    "    cidade = match['metadata']['cidade']\n",
    "    \n",
    "    print(f\"\\n{i}. **{cidade.upper()}** (Score: {score:.3f})\")\n",
    "    print(f\"   {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5fea29",
   "metadata": {},
   "source": [
    "## âœ… **Resumo do Notebook 01:**\n",
    "\n",
    "### ğŸ¯ **O que fizemos:**\n",
    "- âš™ï¸ Configuramos o Pinecone Cloud\n",
    "- ğŸ—„ï¸ Criamos Ã­ndice vetorial \"turismo-inteligente\"\n",
    "- ğŸ“š Indexamos 20 documentos turÃ­sticos (Rio + Paris)\n",
    "- ğŸ§  Usamos embeddings sentence-transformers\n",
    "- âœ… Testamos busca por similaridade\n",
    "\n",
    "### ğŸ“Š **Dados Indexados:**\n",
    "- ğŸ‡§ğŸ‡· **Rio**: 10 docs (5 roteiros + 5 logÃ­stica)\n",
    "- ğŸ‡«ğŸ‡· **Paris**: 10 docs (5 roteiros + 5 logÃ­stica)\n",
    "- ğŸ“ **DimensÃ£o**: 384 (all-MiniLM-L6-v2)\n",
    "\n",
    "### â¡ï¸ **PrÃ³ximo Passo:**\n",
    "**02-RAG.ipynb** â†’ Sistema de recuperaÃ§Ã£o inteligente\n",
    "\n",
    "---\n",
    "âœ¨ **Base vetorial pronta para uso!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4115c3c",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ **VisualizaÃ§Ã£o dos Dados Carregados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25f00f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ **CONTEÃšDO DETALHADO DA BASE DE CONHECIMENTO:**\\n\n",
      "ğŸ–ï¸ RIO DE JANEIRO - ROTEIROS:\n",
      "   1. Cristo Redentor: Uma das Sete Maravilhas do Mundo Moderno, localizado no Corcovado.\n",
      "   2. PÃ£o de AÃ§Ãºcar: Bondinho famoso com vista panorÃ¢mica da cidade e praias.\n",
      "   3. Praia de Copacabana: 4km de areia branca, calÃ§adÃ£o famoso, hotÃ©is luxuosos.\n",
      "   4. Praia de Ipanema: Bairro sofisticado, praia das celebridades, pÃ´r do sol inesquecÃ­vel.\n",
      "   5. Santa Teresa: Bairro boÃªmio, casarÃµes coloniais, ateliÃªs de artistas.\n",
      "\n",
      "ğŸ–ï¸ RIO DE JANEIRO - LOGÃSTICA:\n",
      "   1. Aeroporto GaleÃ£o: Principal aeroporto internacional, 20km do centro.\n",
      "   2. Aeroporto Santos Dumont: Aeroporto domÃ©stico no centro da cidade, voos nacionais, vista privilegiada da BaÃ­a de Guanabara.\n",
      "   3. Metro Rio: Linhas 1, 2 e 4 conectam principais pontos turÃ­sticos.\n",
      "   4. Uber/99: DisponÃ­vel 24h, mais seguro que tÃ¡xi comum.\n",
      "   5. BRT: Ã”nibus rÃ¡pido conecta Barra da Tijuca ao centro.\n",
      "   6. Hospedagem Copacabana: HotÃ©is de todas as categorias na orla.\n",
      "\n",
      "ğŸ—¼ PARIS - ROTEIROS:\n",
      "   1. Torre Eiffel: SÃ­mbolo de Paris, 324m de altura, iluminaÃ§Ã£o noturna espetacular.\n",
      "   2. Museu do Louvre: Maior museu do mundo, Mona Lisa, arte clÃ¡ssica.\n",
      "   3. Notre-Dame: Catedral gÃ³tica, arquitetura medieval, Ile de la CitÃ©.\n",
      "   4. Champs-Ã‰lysÃ©es: Avenida mais famosa, compras, cafÃ©s, Arc de Triomphe.\n",
      "   5. Montmartre: Bairro artÃ­stico, SacrÃ©-CÅ“ur, cabarÃ©s, vista panorÃ¢mica.\n",
      "\n",
      "ğŸ—¼ PARIS - LOGÃSTICA:\n",
      "   1. Charles de Gaulle: Principal aeroporto, RER B conecta ao centro em 45min.\n",
      "   2. Metro Paris: 14 linhas, passe Navigo, funciona atÃ© 1h15 (2h15 sexta/sÃ¡bado).\n",
      "   3. Uber/Taxi: DisponÃ­vel, mas metro Ã© mais rÃ¡pido no centro.\n",
      "   4. Hotel Le Marais: Bairro histÃ³rico, walking distance de atraÃ§Ãµes.\n",
      "   5. Velib: Sistema de bikes compartilhadas, ideal para curtas distÃ¢ncias.\n",
      "\n",
      "ğŸ“Š **ESTATÃSTICAS DETALHADAS:**\n",
      "   ğŸ“ˆ Total geral: 21 documentos\n",
      "   ğŸ™ï¸ Por cidade: Rio (11) | Paris (10)\n",
      "   ğŸ“ Por tipo: Roteiros (10) | LogÃ­stica (11)\n",
      "\\nğŸ¯ **Vantagem:** Dados centralizados e fÃ¡ceis de manter!\n"
     ]
    }
   ],
   "source": [
    "# Demonstrar o conteÃºdo carregado do arquivo\n",
    "print(\"ğŸ“‹ **CONTEÃšDO DETALHADO DA BASE DE CONHECIMENTO:**\\\\n\")\n",
    "\n",
    "for categoria, documentos in dados_turismo.items():\n",
    "    cidade = \"ğŸ–ï¸ RIO DE JANEIRO\" if \"rio\" in categoria else \"ğŸ—¼ PARIS\"\n",
    "    tipo = \"ROTEIROS\" if \"roteiros\" in categoria else \"LOGÃSTICA\"\n",
    "    \n",
    "    print(f\"{cidade} - {tipo}:\")\n",
    "    for i, doc in enumerate(documentos, 1):\n",
    "        print(f\"   {i}. {doc}\")\n",
    "    print()\n",
    "\n",
    "# Calcular estatÃ­sticas bÃ¡sicas\n",
    "total_geral = sum(len(docs) for docs in dados_turismo.values())\n",
    "rio_total = sum(len(docs) for cat, docs in dados_turismo.items() if \"rio\" in cat)\n",
    "paris_total = sum(len(docs) for cat, docs in dados_turismo.items() if \"paris\" in cat)\n",
    "roteiros_total = sum(len(docs) for cat, docs in dados_turismo.items() if \"roteiros\" in cat)\n",
    "logistica_total = sum(len(docs) for cat, docs in dados_turismo.items() if \"logistica\" in cat)\n",
    "\n",
    "print(\"ğŸ“Š **ESTATÃSTICAS DETALHADAS:**\")\n",
    "print(f\"   ğŸ“ˆ Total geral: {total_geral} documentos\")\n",
    "print(f\"   ğŸ™ï¸ Por cidade: Rio ({rio_total}) | Paris ({paris_total})\")\n",
    "print(f\"   ğŸ“ Por tipo: Roteiros ({roteiros_total}) | LogÃ­stica ({logistica_total})\")\n",
    "\n",
    "print(\"\\\\nğŸ¯ **Vantagem:** Dados centralizados e fÃ¡ceis de manter!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
