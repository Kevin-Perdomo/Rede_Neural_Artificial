{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94f8859c",
   "metadata": {},
   "source": [
    "# Populando o Pinecone com Base de Conhecimento\n",
    "Indexação de informações turísticas de Rio de Janeiro e Paris para uso no RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4decd7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pinecone import Pinecone\n",
    "pinecone_client = Pinecone()\n",
    "indice = pinecone_client.Index('turismo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a510db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar base de conhecimento e dividir em chunks\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Carregar base de conhecimento\n",
    "with open('base_conhecimento_rio_paris.txt', 'r', encoding='utf-8') as f:\n",
    "    texto = f.read()\n",
    "\n",
    "# Separar em chunks (ajuste chunk_size conforme necessário)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "chunks = text_splitter.create_documents([texto])\n",
    "\n",
    "# Gerar embeddings para cada chunk\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "ids = [f'chunk_{i}' for i in range(len(chunks))]\n",
    "vetores = [embeddings_model.embed_documents([chunk.page_content])[0] for chunk in chunks]\n",
    "\n",
    "# Popular o Pinecone com os embeddings reais\n",
    "indice.upsert(vectors=list(zip(ids, vetores)))\n",
    "\n",
    "print(f\"{len(chunks)} chunks indexados no Pinecone!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
