{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94f8859c",
   "metadata": {},
   "source": [
    "# 📚 Populando o Pinecone com Base de Conhecimento\n",
    "\n",
    "**Objetivo**: Indexar informações turísticas de Rio de Janeiro e Paris para uso no sistema RAG.\n",
    "\n",
    "## 📋 Ordem de Execução:\n",
    "1. **Célula 2**: Conectar ao Pinecone\n",
    "2. **Célula 3**: Carregar e dividir texto em chunks\n",
    "3. **Célula 4**: Carregar modelo de embeddings (demora na 1ª vez)\n",
    "4. **Célula 5**: Gerar embeddings e inserir no Pinecone\n",
    "5. **Célula 6**: Testar busca por similaridade\n",
    "\n",
    "## ✅ Status Atual:\n",
    "- ✅ Índice 'guia-viagem' criado (384 dimensões)\n",
    "- ✅ 4 chunks indexados com metadados\n",
    "- ✅ Busca por similaridade funcionando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4decd7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado ao índice 'guia-viagem' com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pinecone import Pinecone\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carregar variáveis de ambiente\n",
    "load_dotenv()\n",
    "\n",
    "# Conectar ao Pinecone\n",
    "pinecone_client = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))\n",
    "indice = pinecone_client.Index('guia-viagem')\n",
    "\n",
    "print(\"Conectado ao índice 'guia-viagem' com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76a510db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Texto dividido em 4 chunks.\n",
      "📄 Exemplo do primeiro chunk: # Base de Conhecimento - Rio de Janeiro\n",
      "Pão de Açúcar: Um dos pontos turísticos mais famosos do Rio,...\n",
      "📏 Tamanho médio dos chunks: 211 caracteres\n"
     ]
    }
   ],
   "source": [
    "# Carregar base de conhecimento e dividir em chunks\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import numpy as np\n",
    "\n",
    "# Carregar base de conhecimento\n",
    "with open('base_conhecimento_rio_paris.txt', 'r', encoding='utf-8') as f:\n",
    "    texto = f.read()\n",
    "\n",
    "# Separar em chunks (ajuste chunk_size conforme necessário)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "chunks = text_splitter.create_documents([texto])\n",
    "\n",
    "print(f\"✅ Texto dividido em {len(chunks)} chunks.\")\n",
    "print(f\"📄 Exemplo do primeiro chunk: {chunks[0].page_content[:100]}...\")\n",
    "print(f\"📏 Tamanho médio dos chunks: {sum(len(chunk.page_content) for chunk in chunks) // len(chunks)} caracteres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7155fed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Carregando modelo de embeddings...\n",
      "✅ Modelo carregado com sucesso!\n",
      "✅ Modelo carregado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Carregar modelo de embeddings (pode demorar na primeira vez)\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "print(\"🔄 Carregando modelo de embeddings...\")\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=model_name)\n",
    "print(\"✅ Modelo carregado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3eba80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Gerando embeddings dos chunks...\n",
      "📊 Processando chunk 4/4\n",
      "✅ Embeddings gerados para 4 chunks!\n",
      "🔄 Inserindo vetores no Pinecone...\n",
      "\n",
      "✅ Embeddings gerados para 4 chunks!\n",
      "🔄 Inserindo vetores no Pinecone...\n",
      "✅ Vetores inseridos com sucesso!\n",
      "📊 Estatísticas do índice: {'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 4}},\n",
      " 'total_vector_count': 4,\n",
      " 'vector_type': 'dense'}\n",
      "✅ Vetores inseridos com sucesso!\n",
      "📊 Estatísticas do índice: {'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 4}},\n",
      " 'total_vector_count': 4,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "# Gerar embeddings e inserir no Pinecone\n",
    "print(\"🔄 Gerando embeddings dos chunks...\")\n",
    "\n",
    "# Preparar dados para inserção\n",
    "vetores_para_inserir = []\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"📊 Processando chunk {i+1}/{len(chunks)}\", end=\"\\r\")\n",
    "    \n",
    "    # Gerar embedding\n",
    "    embedding = embeddings_model.embed_documents([chunk.page_content])[0]\n",
    "    \n",
    "    # Preparar vetor com metadados\n",
    "    vetor = {\n",
    "        'id': f'chunk_{i}',\n",
    "        'values': embedding,\n",
    "        'metadata': {\n",
    "            'text': chunk.page_content,\n",
    "            'source': 'base_conhecimento_rio_paris.txt',\n",
    "            'chunk_index': i\n",
    "        }\n",
    "    }\n",
    "    vetores_para_inserir.append(vetor)\n",
    "\n",
    "print(f\"\\n✅ Embeddings gerados para {len(chunks)} chunks!\")\n",
    "\n",
    "# Inserir no Pinecone\n",
    "print(\"🔄 Inserindo vetores no Pinecone...\")\n",
    "indice.upsert(vectors=vetores_para_inserir)\n",
    "print(\"✅ Vetores inseridos com sucesso!\")\n",
    "\n",
    "# Verificar estatísticas\n",
    "stats = indice.describe_index_stats()\n",
    "print(f\"📊 Estatísticas do índice: {stats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67460ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Testando busca por similaridade:\n",
      "Consulta: Quais são os pontos turísticos do Rio de Janeiro?\n",
      "\n",
      "Resultados encontrados:\n",
      "ID: chunk_0\n",
      "Similaridade: 0.729\n",
      "Texto: # Base de Conhecimento - Rio de Janeiro\n",
      "Pão de Açúcar: Um dos pontos turísticos mais famosos do Rio, com vista panorâmica da cidade.\n",
      "Cristo Redentor: ...\n",
      "--------------------------------------------------\n",
      "ID: chunk_1\n",
      "Similaridade: 0.505\n",
      "Texto: Restaurante Aprazível: Restaurante de comida brasileira contemporânea em Santa Teresa.\n",
      "Dica: Evite ostentar objetos de valor em áreas turísticas movim...\n",
      "--------------------------------------------------\n",
      "ID: chunk_2\n",
      "Similaridade: 0.431\n",
      "Texto: # Base de Conhecimento - Paris\n",
      "Torre Eiffel: Principal símbolo de Paris, ideal para visitação diurna e noturna.\n",
      "Museu do Louvre: Maior museu de arte d...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Testar busca por similaridade\n",
    "query = \"Quais são os pontos turísticos do Rio de Janeiro?\"\n",
    "query_embedding = embeddings_model.embed_documents([query])[0]\n",
    "\n",
    "# Buscar documentos similares\n",
    "resultado = indice.query(vector=query_embedding, top_k=3, include_metadata=True)\n",
    "\n",
    "print(\"🔍 Testando busca por similaridade:\")\n",
    "print(f\"Consulta: {query}\")\n",
    "print(\"\\nResultados encontrados:\")\n",
    "for match in resultado['matches']:\n",
    "    print(f\"ID: {match['id']}\")\n",
    "    print(f\"Similaridade: {match['score']:.3f}\")\n",
    "    print(f\"Texto: {match['metadata']['text'][:150]}...\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
