{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94f8859c",
   "metadata": {},
   "source": [
    "# ğŸ“š Populando o Pinecone com Base de Conhecimento\n",
    "\n",
    "**Objetivo**: Indexar informaÃ§Ãµes turÃ­sticas de Rio de Janeiro e Paris para uso no sistema RAG.\n",
    "\n",
    "## ğŸ“‹ Ordem de ExecuÃ§Ã£o:\n",
    "1. **CÃ©lula 2**: Conectar ao Pinecone\n",
    "2. **CÃ©lula 3**: Carregar e dividir texto em chunks\n",
    "3. **CÃ©lula 4**: Carregar modelo de embeddings (demora na 1Âª vez)\n",
    "4. **CÃ©lula 5**: Gerar embeddings e inserir no Pinecone\n",
    "5. **CÃ©lula 6**: Testar busca por similaridade\n",
    "\n",
    "## âœ… Status Atual:\n",
    "- âœ… Ãndice 'guia-viagem' criado (384 dimensÃµes)\n",
    "- âœ… 4 chunks indexados com metadados\n",
    "- âœ… Busca por similaridade funcionando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4decd7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado ao Ã­ndice 'guia-viagem' com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pinecone import Pinecone\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carregar variÃ¡veis de ambiente\n",
    "load_dotenv()\n",
    "\n",
    "# Conectar ao Pinecone\n",
    "pinecone_client = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))\n",
    "indice = pinecone_client.Index('guia-viagem')\n",
    "\n",
    "print(\"Conectado ao Ã­ndice 'guia-viagem' com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76a510db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Texto dividido em 4 chunks.\n",
      "ğŸ“„ Exemplo do primeiro chunk: # Base de Conhecimento - Rio de Janeiro\n",
      "PÃ£o de AÃ§Ãºcar: Um dos pontos turÃ­sticos mais famosos do Rio,...\n",
      "ğŸ“ Tamanho mÃ©dio dos chunks: 211 caracteres\n"
     ]
    }
   ],
   "source": [
    "# Carregar base de conhecimento e dividir em chunks\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import numpy as np\n",
    "\n",
    "# Carregar base de conhecimento\n",
    "with open('base_conhecimento_rio_paris.txt', 'r', encoding='utf-8') as f:\n",
    "    texto = f.read()\n",
    "\n",
    "# Separar em chunks (ajuste chunk_size conforme necessÃ¡rio)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "chunks = text_splitter.create_documents([texto])\n",
    "\n",
    "print(f\"âœ… Texto dividido em {len(chunks)} chunks.\")\n",
    "print(f\"ğŸ“„ Exemplo do primeiro chunk: {chunks[0].page_content[:100]}...\")\n",
    "print(f\"ğŸ“ Tamanho mÃ©dio dos chunks: {sum(len(chunk.page_content) for chunk in chunks) // len(chunks)} caracteres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7155fed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Carregando modelo de embeddings...\n",
      "âœ… Modelo carregado com sucesso!\n",
      "âœ… Modelo carregado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Carregar modelo de embeddings (pode demorar na primeira vez)\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "print(\"ğŸ”„ Carregando modelo de embeddings...\")\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=model_name)\n",
    "print(\"âœ… Modelo carregado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3eba80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Gerando embeddings dos chunks...\n",
      "ğŸ“Š Processando chunk 4/4\n",
      "âœ… Embeddings gerados para 4 chunks!\n",
      "ğŸ”„ Inserindo vetores no Pinecone...\n",
      "\n",
      "âœ… Embeddings gerados para 4 chunks!\n",
      "ğŸ”„ Inserindo vetores no Pinecone...\n",
      "âœ… Vetores inseridos com sucesso!\n",
      "ğŸ“Š EstatÃ­sticas do Ã­ndice: {'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 4}},\n",
      " 'total_vector_count': 4,\n",
      " 'vector_type': 'dense'}\n",
      "âœ… Vetores inseridos com sucesso!\n",
      "ğŸ“Š EstatÃ­sticas do Ã­ndice: {'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 4}},\n",
      " 'total_vector_count': 4,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "# Gerar embeddings e inserir no Pinecone\n",
    "print(\"ğŸ”„ Gerando embeddings dos chunks...\")\n",
    "\n",
    "# Preparar dados para inserÃ§Ã£o\n",
    "vetores_para_inserir = []\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"ğŸ“Š Processando chunk {i+1}/{len(chunks)}\", end=\"\\r\")\n",
    "    \n",
    "    # Gerar embedding\n",
    "    embedding = embeddings_model.embed_documents([chunk.page_content])[0]\n",
    "    \n",
    "    # Preparar vetor com metadados\n",
    "    vetor = {\n",
    "        'id': f'chunk_{i}',\n",
    "        'values': embedding,\n",
    "        'metadata': {\n",
    "            'text': chunk.page_content,\n",
    "            'source': 'base_conhecimento_rio_paris.txt',\n",
    "            'chunk_index': i\n",
    "        }\n",
    "    }\n",
    "    vetores_para_inserir.append(vetor)\n",
    "\n",
    "print(f\"\\nâœ… Embeddings gerados para {len(chunks)} chunks!\")\n",
    "\n",
    "# Inserir no Pinecone\n",
    "print(\"ğŸ”„ Inserindo vetores no Pinecone...\")\n",
    "indice.upsert(vectors=vetores_para_inserir)\n",
    "print(\"âœ… Vetores inseridos com sucesso!\")\n",
    "\n",
    "# Verificar estatÃ­sticas\n",
    "stats = indice.describe_index_stats()\n",
    "print(f\"ğŸ“Š EstatÃ­sticas do Ã­ndice: {stats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67460ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Testando busca por similaridade:\n",
      "Consulta: Quais sÃ£o os pontos turÃ­sticos do Rio de Janeiro?\n",
      "\n",
      "Resultados encontrados:\n",
      "ID: chunk_0\n",
      "Similaridade: 0.729\n",
      "Texto: # Base de Conhecimento - Rio de Janeiro\n",
      "PÃ£o de AÃ§Ãºcar: Um dos pontos turÃ­sticos mais famosos do Rio, com vista panorÃ¢mica da cidade.\n",
      "Cristo Redentor: ...\n",
      "--------------------------------------------------\n",
      "ID: chunk_1\n",
      "Similaridade: 0.505\n",
      "Texto: Restaurante AprazÃ­vel: Restaurante de comida brasileira contemporÃ¢nea em Santa Teresa.\n",
      "Dica: Evite ostentar objetos de valor em Ã¡reas turÃ­sticas movim...\n",
      "--------------------------------------------------\n",
      "ID: chunk_2\n",
      "Similaridade: 0.431\n",
      "Texto: # Base de Conhecimento - Paris\n",
      "Torre Eiffel: Principal sÃ­mbolo de Paris, ideal para visitaÃ§Ã£o diurna e noturna.\n",
      "Museu do Louvre: Maior museu de arte d...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Testar busca por similaridade\n",
    "query = \"Quais sÃ£o os pontos turÃ­sticos do Rio de Janeiro?\"\n",
    "query_embedding = embeddings_model.embed_documents([query])[0]\n",
    "\n",
    "# Buscar documentos similares\n",
    "resultado = indice.query(vector=query_embedding, top_k=3, include_metadata=True)\n",
    "\n",
    "print(\"ğŸ” Testando busca por similaridade:\")\n",
    "print(f\"Consulta: {query}\")\n",
    "print(\"\\nResultados encontrados:\")\n",
    "for match in resultado['matches']:\n",
    "    print(f\"ID: {match['id']}\")\n",
    "    print(f\"Similaridade: {match['score']:.3f}\")\n",
    "    print(f\"Texto: {match['metadata']['text'][:150]}...\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
