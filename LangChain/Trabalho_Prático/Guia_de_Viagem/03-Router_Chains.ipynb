{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa9b8a53",
   "metadata": {},
   "source": [
    "# üß≠ Sistema de Router Chains - Guia de Viagem\n",
    "\n",
    "**Objetivo**: Implementar um sistema inteligente que classifica consultas tur√≠sticas e direciona para chains especializadas.\n",
    "\n",
    "## üéØ Tipos de Consulta Suportadas:\n",
    "1. **`roteiro-viagem`**: Planejamento de roteiros e itiner√°rios\n",
    "2. **`logistica-transporte`**: Informa√ß√µes sobre transporte e log√≠stica\n",
    "3. **`info-local`**: Dados sobre pontos tur√≠sticos, restaurantes, cultura\n",
    "4. **`traducao-idiomas`**: Tradu√ß√£o e comunica√ß√£o em outros idiomas\n",
    "\n",
    "## üìã Arquitetura:\n",
    "- **Router Chain**: Classifica a inten√ß√£o da consulta\n",
    "- **Chains Especializadas**: Processam cada tipo de consulta\n",
    "- **RAG Integration**: Usa dados do Pinecone para respostas contextualizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81e1ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports e configura√ß√£o inicial\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Carregar vari√°veis de ambiente\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Imports carregados com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7444d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar componentes principais\n",
    "print(\"üîÑ Inicializando componentes...\")\n",
    "\n",
    "# LLM Groq\n",
    "llm = ChatGroq(\n",
    "    temperature=0.1,\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    groq_api_key=os.getenv('GROQ_API_KEY')\n",
    ")\n",
    "\n",
    "# Pinecone e embeddings (do notebook anterior)\n",
    "pinecone_client = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))\n",
    "indice = pinecone_client.Index('guia-viagem')\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "print(\"‚úÖ Componentes inicializados:\")\n",
    "print(f\"ü§ñ LLM: {llm.model_name}\")\n",
    "print(f\"üóÇÔ∏è Pinecone: {indice.describe_index_stats()['total_vector_count']} vetores\")\n",
    "print(f\"üéØ Embeddings: {embeddings_model.model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3738638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir prompts especializados para cada tipo de consulta\n",
    "\n",
    "# 1. Template para Roteiro de Viagem\n",
    "roteiro_template = \"\"\"\n",
    "Voc√™ √© um especialista em planejamento de roteiros tur√≠sticos. Use o contexto fornecido para criar roteiros detalhados.\n",
    "\n",
    "CONTEXTO RELEVANTE:\n",
    "{context}\n",
    "\n",
    "CONSULTA DO USU√ÅRIO:\n",
    "{input}\n",
    "\n",
    "INSTRU√á√ïES:\n",
    "- Crie um roteiro estruturado e detalhado\n",
    "- Inclua hor√°rios sugeridos e dura√ß√£o das atividades\n",
    "- Considere proximidade geogr√°fica dos pontos\n",
    "- Adicione dicas pr√°ticas e recomenda√ß√µes\n",
    "\n",
    "RESPOSTA:\n",
    "\"\"\"\n",
    "\n",
    "# 2. Template para Log√≠stica e Transporte\n",
    "logistica_template = \"\"\"\n",
    "Voc√™ √© um especialista em log√≠stica de viagem e sistemas de transporte urbano. Use o contexto para orientar sobre mobilidade.\n",
    "\n",
    "CONTEXTO RELEVANTE:\n",
    "{context}\n",
    "\n",
    "CONSULTA DO USU√ÅRIO:\n",
    "{input}\n",
    "\n",
    "INSTRU√á√ïES:\n",
    "- Forne√ßa informa√ß√µes detalhadas sobre transporte\n",
    "- Inclua custos, hor√°rios e rotas quando poss√≠vel\n",
    "- Sugira alternativas de transporte\n",
    "- D√™ dicas de seguran√ßa e efici√™ncia\n",
    "\n",
    "RESPOSTA:\n",
    "\"\"\"\n",
    "\n",
    "# 3. Template para Informa√ß√µes Locais\n",
    "info_local_template = \"\"\"\n",
    "Voc√™ √© um guia tur√≠stico local expert. Use o contexto fornecido para dar informa√ß√µes detalhadas sobre pontos tur√≠sticos, cultura e recomenda√ß√µes.\n",
    "\n",
    "CONTEXTO RELEVANTE:\n",
    "{context}\n",
    "\n",
    "CONSULTA DO USU√ÅRIO:\n",
    "{input}\n",
    "\n",
    "INSTRU√á√ïES:\n",
    "- Forne√ßa informa√ß√µes detalhadas e precisas\n",
    "- Inclua dados hist√≥ricos, culturais ou curiosidades\n",
    "- Adicione recomenda√ß√µes pr√°ticas (hor√°rios, pre√ßos, dicas)\n",
    "- Mantenha um tom acolhedor e informativo\n",
    "\n",
    "RESPOSTA:\n",
    "\"\"\"\n",
    "\n",
    "# 4. Template para Tradu√ß√£o e Idiomas\n",
    "traducao_template = \"\"\"\n",
    "Voc√™ √© um assistente de tradu√ß√£o e comunica√ß√£o intercultural. Ajude com tradu√ß√µes, frases √∫teis e orienta√ß√µes culturais.\n",
    "\n",
    "CONTEXTO RELEVANTE:\n",
    "{context}\n",
    "\n",
    "CONSULTA DO USU√ÅRIO:\n",
    "{input}\n",
    "\n",
    "INSTRU√á√ïES:\n",
    "- Forne√ßa tradu√ß√µes precisas e contextualizadas\n",
    "- Inclua pron√∫ncia quando relevante\n",
    "- Adicione informa√ß√µes sobre etiqueta cultural\n",
    "- Sugira frases alternativas para diferentes situa√ß√µes\n",
    "\n",
    "RESPOSTA:\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚úÖ Templates de prompt definidos para 4 categorias!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e01c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para buscar contexto relevante no Pinecone\n",
    "def buscar_contexto_relevante(consulta, top_k=3):\n",
    "    \"\"\"\n",
    "    Busca informa√ß√µes relevantes no Pinecone baseado na consulta do usu√°rio.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Gerar embedding da consulta\n",
    "        query_embedding = embeddings_model.embed_documents([consulta])[0]\n",
    "        \n",
    "        # Buscar no Pinecone\n",
    "        resultado = indice.query(\n",
    "            vector=query_embedding, \n",
    "            top_k=top_k, \n",
    "            include_metadata=True\n",
    "        )\n",
    "        \n",
    "        # Extrair textos relevantes\n",
    "        contextos = []\n",
    "        for match in resultado['matches']:\n",
    "            if match['score'] > 0.3:  # Filtro de relev√¢ncia\n",
    "                contextos.append(match['metadata']['text'])\n",
    "        \n",
    "        return \"\\n\\n\".join(contextos) if contextos else \"Nenhum contexto espec√≠fico encontrado na base de conhecimento.\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro na busca: {e}\")\n",
    "        return \"Erro ao buscar contexto na base de conhecimento.\"\n",
    "\n",
    "# Testar a fun√ß√£o\n",
    "teste_contexto = buscar_contexto_relevante(\"pontos tur√≠sticos do Rio de Janeiro\")\n",
    "print(\"üîç Teste da busca de contexto:\")\n",
    "print(f\"Primeiros 200 caracteres: {teste_contexto[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar chains especializadas com RAG\n",
    "def criar_chain_com_rag(template, nome):\n",
    "    \"\"\"\n",
    "    Cria uma chain que integra RAG (busca no Pinecone) com o template espec√≠fico.\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"input\", \"context\"]\n",
    "    )\n",
    "    \n",
    "    def chain_com_contexto(consulta):\n",
    "        # Buscar contexto relevante\n",
    "        contexto = buscar_contexto_relevante(consulta)\n",
    "        \n",
    "        # Executar chain com contexto\n",
    "        chain = LLMChain(llm=llm, prompt=prompt)\n",
    "        return chain.run(input=consulta, context=contexto)\n",
    "    \n",
    "    return chain_com_contexto\n",
    "\n",
    "# Criar as 4 chains especializadas\n",
    "chains = {\n",
    "    \"roteiro-viagem\": criar_chain_com_rag(roteiro_template, \"Roteiro de Viagem\"),\n",
    "    \"logistica-transporte\": criar_chain_com_rag(logistica_template, \"Log√≠stica e Transporte\"),\n",
    "    \"info-local\": criar_chain_com_rag(info_local_template, \"Informa√ß√µes Locais\"),\n",
    "    \"traducao-idiomas\": criar_chain_com_rag(traducao_template, \"Tradu√ß√£o e Idiomas\")\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Chains especializadas criadas:\")\n",
    "for nome in chains.keys():\n",
    "    print(f\"üìã {nome}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d236cf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o Router Chain para classificar consultas\n",
    "router_template = \"\"\"\n",
    "Voc√™ √© um classificador de consultas tur√≠sticas. Analise a consulta do usu√°rio e determine qual categoria ela pertence.\n",
    "\n",
    "CATEGORIAS DISPON√çVEIS:\n",
    "- roteiro-viagem: Planejamento de roteiros, itiner√°rios, programa√ß√£o de atividades\n",
    "- logistica-transporte: Transporte, como chegar, mobilidade urbana, hor√°rios\n",
    "- info-local: Informa√ß√µes sobre pontos tur√≠sticos, restaurantes, cultura, hist√≥ria\n",
    "- traducao-idiomas: Tradu√ß√£o, frases √∫teis, comunica√ß√£o, idiomas\n",
    "\n",
    "CONSULTA: {input}\n",
    "\n",
    "INSTRU√á√ïES:\n",
    "- Responda APENAS com o nome da categoria\n",
    "- Use exatamente os nomes: roteiro-viagem, logistica-transporte, info-local, ou traducao-idiomas\n",
    "- Se n√£o tiver certeza, use 'info-local' como padr√£o\n",
    "\n",
    "CATEGORIA:\n",
    "\"\"\"\n",
    "\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "\n",
    "router_chain = LLMChain(llm=llm, prompt=router_prompt)\n",
    "\n",
    "print(\"‚úÖ Router Chain criado para classifica√ß√£o de consultas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e5f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sistema principal - Guia de Viagem Inteligente\n",
    "def guia_viagem_inteligente(consulta_usuario):\n",
    "    \"\"\"\n",
    "    Sistema principal que processa consultas tur√≠sticas:\n",
    "    1. Classifica a consulta\n",
    "    2. Direciona para a chain apropriada\n",
    "    3. Retorna resposta contextualizada com RAG\n",
    "    \"\"\"\n",
    "    print(f\"üîç Processando consulta: '{consulta_usuario}'\")\n",
    "    \n",
    "    try:\n",
    "        # Passo 1: Classificar a consulta\n",
    "        categoria = router_chain.run(consulta_usuario).strip().lower()\n",
    "        print(f\"üìÇ Categoria identificada: {categoria}\")\n",
    "        \n",
    "        # Passo 2: Verificar se a categoria √© v√°lida\n",
    "        if categoria not in chains:\n",
    "            print(f\"‚ö†Ô∏è Categoria '{categoria}' n√£o reconhecida. Usando 'info-local' como padr√£o.\")\n",
    "            categoria = \"info-local\"\n",
    "        \n",
    "        # Passo 3: Executar a chain especializada\n",
    "        print(f\"ü§ñ Executando chain especializada: {categoria}\")\n",
    "        resposta = chains[categoria](consulta_usuario)\n",
    "        \n",
    "        # Passo 4: Retornar resultado estruturado\n",
    "        resultado = {\n",
    "            \"consulta\": consulta_usuario,\n",
    "            \"categoria\": categoria,\n",
    "            \"resposta\": resposta\n",
    "        }\n",
    "        \n",
    "        return resultado\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro no processamento: {e}\")\n",
    "        return {\n",
    "            \"consulta\": consulta_usuario,\n",
    "            \"categoria\": \"erro\",\n",
    "            \"resposta\": f\"Desculpe, ocorreu um erro ao processar sua consulta: {e}\"\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Sistema Guia de Viagem Inteligente configurado!\")\n",
    "print(\"üéØ Pronto para processar consultas tur√≠sticas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2f07b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testes do sistema com diferentes tipos de consulta\n",
    "consultas_teste = [\n",
    "    \"Quais s√£o os principais pontos tur√≠sticos do Rio de Janeiro?\",\n",
    "    \"Como posso criar um roteiro de 2 dias em Paris?\",\n",
    "    \"Como chegar do aeroporto ao centro do Rio?\",\n",
    "    \"Como dizer 'onde fica o banheiro?' em franc√™s?\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Iniciando testes do sistema...\\n\")\n",
    "\n",
    "for i, consulta in enumerate(consultas_teste, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TESTE {i}:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    resultado = guia_viagem_inteligente(consulta)\n",
    "    \n",
    "    print(f\"\\nüìù RESULTADO:\")\n",
    "    print(f\"üìÇ Categoria: {resultado['categoria']}\")\n",
    "    print(f\"üí¨ Resposta: {resultado['resposta'][:300]}...\")\n",
    "    print(f\"\\n{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
